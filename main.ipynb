{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86648c93-943b-4148-be8c-b86c23072b5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Applications Processing Automation\n",
    "\n",
    "(*By: [@mahmoud-elmakki](https://github.com/mahmoud-elmakki)*)\n",
    "\n",
    "The purpose of this code is to automate the first trivial filtering steps in the processing of the applications for the TReND in Africa Computational Neuroscience and Machine Learning Basics course.\n",
    "\n",
    "This code is organized as a set of functions to be applied as a processing pipeline on the application responses data (See [documentation](https://docs.google.com/document/d/1n4pMEOgMuenuFpN6zXQtZlpYFXwPat2P4-SzZaN8mFg/edit?usp=drivesdk)).\n",
    "\n",
    "### **How to use (as a developer):**\n",
    "Just clone the Github repository and get into the business!\\\n",
    "If you have anaconda and yupyter installed locally you can just clone the repory directly on your machine. Elsewise, you can clone it into Google Colab.\n",
    "(In either case, don't forget to regularly pull and push changes).\n",
    "\n",
    "### **How to use (as a reviewer):**\n",
    "If you are on Github now, open this notebook in Google Colab, or clone the whole repo locally, so you can run the cells. In case of running it in Colab, don't forget to save and download the resulting Excel sheet of the processed responses into a local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5561a65-902a-424b-bc94-4b417849e29e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b154dc7-4f8f-4d8f-8417-5108fb288621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that you have to download the responses data Excel sheet from Google Drive and put it in the same folder as the code.\n",
    "# You don't have to do this if you cloned the Github repo (all will be organized in the repo).\n",
    " \n",
    "# TODO: Load data directly from Google Drive.\n",
    "\n",
    "# Loading students responses data\n",
    "STD_DATA_DIR = './responses_data/TReND Comp Neuro application form Rwanda 2024 (Responses).xlsx'\n",
    "std_raw_responses_df = pd.read_excel(STD_DATA_DIR)\n",
    "\n",
    "# Loading references responses data\n",
    "REF_DATA_DIR = './responses_data/Recommendation-Letter-Portal.xlsx'\n",
    "ref_raw_responses_df = pd.read_excel(REF_DATA_DIR)\n",
    "\n",
    "# Adding two columns to the responses DataFrame (initialized with None for all cells).\n",
    "std_raw_responses_df['Flag'] = None  #String (\"flagged\" or None)\n",
    "std_raw_responses_df['Notes'] = None #String (Text of notes == reasaons for flagging)\n",
    "std_raw_responses_df['Recommendation Letter 1'] = None\n",
    "std_raw_responses_df['Recommendation Letter 2'] = None\n",
    "\n",
    "# Flag the reference response if they submit more than one letter (keeo the last letter submitted)\n",
    "ref_raw_responses_df['Flag'] = None\n",
    "ref_raw_responses_df['Notes'] = None\n",
    "ref_raw_responses_df['Matched'] = \"unmatched\"\n",
    "\n",
    "# Just specify folder names - thje code will create the directory\n",
    "RESULTS_FOLDER_NAME = \"filtered_responses\"\n",
    "RESULTS_DIR = os.path.join(os.getcwd(), RESULTS_FOLDER_NAME)\n",
    "\n",
    "if not os.path.exists(RESULTS_DIR):\n",
    "    os.mkdir(RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb241b1a-36d9-4e70-bc60-2621fce3c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the minimum and maximun number of words for ansewrs for essay questions.\n",
    "# Note: These parameters apply for for all essay questions.\n",
    "\n",
    "MIN_WORDS_NUM = 10\n",
    "MAX_WORDS_NUM = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f284bde7-b704-48d6-b0c2-86e364335cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_raw_responses_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57ab8a-3870-4752-9ab7-edb7c6dce504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this dictionary as a reference for column names.\n",
    "\n",
    "std_questions_dict = {i: column for i, column in enumerate(std_raw_responses_df.columns)}\n",
    "std_questions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1fde9-e160-464a-8b31-e8731237d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this dictionary as a reference for column names.\n",
    "\n",
    "ref_questions_dict = {i: column for i, column in enumerate(ref_raw_responses_df.columns)}\n",
    "ref_questions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d04d76e-c3c6-4a5e-9dac-1792ef35c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used indices of the student responses DataFrame\n",
    "\n",
    "std_idcs = {\n",
    "    'email_idx' : 1,\n",
    "    'firstname_idx' : 2,\n",
    "    'lastname_idx' : 3,\n",
    "    'ref' : {\n",
    "        'first_ref_email_idx' : 25,\n",
    "        'second_ref_email_idx' : 27\n",
    "          },\n",
    "    'flag_idx' : 28,\n",
    "    'notes_idx' : 29,\n",
    "    'first_recomm_letter_idx' : 30,\n",
    "    'second_recomm_letter_idx' : 31,\n",
    "}\n",
    "\n",
    "# Used indices of the reference responses DataFrame\n",
    "ref_idcs = {\n",
    "    'email_idx' : 1,\n",
    "    'std' : {\n",
    "        'firstname_idx' : 3,\n",
    "        'lastname_idx' : 4,\n",
    "        'email_idx' : 5\n",
    "    },\n",
    "    'letter_idx' : 7,\n",
    "    'flag_idx' : 8,\n",
    "    'notes_idx' : 9,\n",
    "    'matched_idx' : 10\n",
    "}\n",
    "\n",
    "std_str_qs = [std_idcs['email_idx'], std_idcs['firstname_idx'], std_idcs['lastname_idx']]\n",
    "ref_str_qs = [ref_idcs['email_idx'], ref_idcs['std']['email_idx'], ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]\n",
    "\n",
    "std_names = [std_idcs['firstname_idx'], std_idcs['lastname_idx']]\n",
    "ref_names = [ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]\n",
    "\n",
    "# Carefully specify names of the columns to be processed (mostly responses for essay questions).\n",
    "essay_qs = [20, 21, 22]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44138fe5-309e-4f87-ad94-532b52df55d3",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb2db56-8054-4e0f-9ec9-0748f2937a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(answer):\n",
    "    \"\"\"\n",
    "    Takes a specific answer (cell) of a specific essay question and returns the answer's number of words.\n",
    "    \"\"\"\n",
    "    return len(answer.split())\n",
    "\n",
    "\n",
    "def to_lowercase(std_df, std_str_qs, ref_df, ref_str_qs):\n",
    "    \"\"\"\n",
    "    For more rigid string comparisons, convert all answers needed for comparison to lowercase.\n",
    "    \"\"\"\n",
    "    for q in std_str_qs:\n",
    "        std_df[q] = std_df[q].str.lower()\n",
    "        \n",
    "    for q in ref_str_qs:\n",
    "        ref_df[q] = ref_df[q].str.lower()\n",
    "        \n",
    "    return std_df, ref_df\n",
    "\n",
    "\n",
    "def to_uppercase(std_df, std_str_qs, ref_df, ref_str_qs):\n",
    "    \"\"\"\n",
    "    This to bring names back as they were.\n",
    "    \"\"\"\n",
    "    for q in std_str_qs:\n",
    "        std_df[q] = std_df[q].str.title()\n",
    "        \n",
    "    for q in ref_str_qs:\n",
    "        ref_df[q] = ref_df[q].str.title()\n",
    "        \n",
    "    return std_df, ref_df\n",
    "\n",
    "\n",
    "def remove_spaces(std_df, std_str_qs, ref_df, ref_str_qs):\n",
    "    \"\"\"\n",
    "    Remove spaces from names and emails.\n",
    "    \"\"\"\n",
    "    for q in std_str_qs:\n",
    "        std_df[q] = std_df[q].str.replace(\" \", \"\")\n",
    "        \n",
    "    for q in ref_str_qs:\n",
    "        ref_df[q] = ref_df[q].str.replace(\" \", \"\")\n",
    "        \n",
    "    return std_df, ref_df\n",
    "\n",
    "\n",
    "def set_flag(responses_df, email):\n",
    "    \"\"\"\n",
    "    Sets the 'flag' column value to \"flagged\" for a response chosen by it's 'Email address'\n",
    "    \"\"\"\n",
    "    # This modifies the DataFrame itself (i.e change in place)\n",
    "    responses_df.iloc[responses_df[std_idcs['email_idx']] == email, std_idcs['flag_idx']] = \"flagged\"\n",
    "\n",
    "    \n",
    "def leave_note(responses_df, response_index, note_text):\n",
    "    \"\"\"\n",
    "    Appends a note to the 'Notes' column.\n",
    "    \"\"\"\n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    if note_text not in str(edited_responses_df.iloc[response_index, std_idcs['notes_idx']]):\n",
    "        if edited_responses_df.iloc[response_index, std_idcs['notes_idx']] is None:\n",
    "            edited_responses_df.iloc[response_index, std_idcs['notes_idx']] = note_text\n",
    "        else:\n",
    "            edited_responses_df.iloc[response_index, std_idcs['notes_idx']] = str(edited_responses_df.iloc[response_index, std_idcs['notes_idx']]) + \". \" + note_text \n",
    "            \n",
    "    return edited_responses_df\n",
    "    \n",
    "    \n",
    "def column_names_to_indices(df, indices_dict):\n",
    "    \"\"\"\n",
    "    Replaces column names with indices.\n",
    "    \"\"\"\n",
    "    processed_df = df.rename(columns={column: i for i, column in enumerate(indices_dict.values())})\n",
    "\n",
    "    return processed_df\n",
    "\n",
    "\n",
    "def indices_to_column_names(df, indices_dict):\n",
    "    \"\"\"\n",
    "    Replaces indices with column names.\n",
    "    \"\"\"\n",
    "    processed_df = df.rename(columns={i: column for i, column in enumerate(indices_dict.values())})\n",
    "\n",
    "    return processed_df\n",
    "\n",
    "\n",
    "def remove_flagged(df):\n",
    "    \"\"\"\n",
    "    Remove f;agged columns.\n",
    "    \"\"\"\n",
    "    processed_df = df.drop(df[(df[std_idcs['flag_idx']] == 'flagged')].index)\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "\n",
    "def get_unmatched_letters(ref_responses_df):\n",
    "    \"\"\"\n",
    "    Gets unmatched recommendation letters.\n",
    "    \"\"\"\n",
    "    ref_responses_df_unmatched = ref_responses_df.loc[ref_responses_df[ref_idcs['matched_idx']] == \"unmatched\"]\n",
    "    \n",
    "    return ref_responses_df_unmatched\n",
    "\n",
    "\n",
    "def get_std_by_email(std_responses_df, email):\n",
    "    \n",
    "    return std_responses_df.loc[std_responses_df[std_idcs['email_idx']] == email]\n",
    "\n",
    "\n",
    "def get_ref_by_email(ref_responses_df, email):\n",
    "    \n",
    "    return ref_responses_df.loc[ref_responses_df[ref_idcs['email_idx']] == email]\n",
    "\n",
    "\n",
    "def get_std_by_email_from_ref(ref_responses_df, std_email):\n",
    "    \n",
    "    return ref_responses_df.loc[ref_responses_df[ref_idcs['std']['email_idx']] == std_email]\n",
    "\n",
    "\n",
    "def get_std_by_firstname_from_ref(ref_responses_df, firstname):\n",
    "    \n",
    "    return ref_responses_df.loc[ref_responses_df[ref_idcs['std']['firstname_idx']] == firstname]\n",
    "\n",
    "\n",
    "def get_std_by_lastname_from_ref(ref_responses_df, lastname):\n",
    "    \n",
    "    return ref_responses_df.loc[ref_responses_df[ref_idcs['std']['lastname_idx']] == lastname]\n",
    "\n",
    "\n",
    "def get_std_by_firstname_and_lastname_from_ref(ref_responses_df, firstname, lastname):\n",
    "    \n",
    "    return ref_responses_df.loc[(ref_responses_df[ref_idcs['std']['firstname_idx']] == firstname) & (ref_responses_df_final[ref_idcs['std']['lastname_idx']] == lastname)] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a1215f-aea3-47ee-a4e2-a91410822c4a",
   "metadata": {},
   "source": [
    "## Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93f7967-a7e6-47a4-a80c-aa765259dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(responses_df):\n",
    "    \"\"\"\n",
    "    removes duplicated rows (responses) based on 'Email address' and keeps the last response submitted.\n",
    "    Note: Some students may make changes to their responses and submit a new one,\n",
    "    this's why this function keeps the last response submitted and removes preceding ones.\n",
    "    \n",
    "    TODO: Check with the organizers what else is an adequate action.\n",
    "    \n",
    "    params :\n",
    "        response_df: the responses data (DataFrame)\n",
    "    returns:\n",
    "        edited_responses_df: An edited response_df with duplicates removed\n",
    "    \"\"\"\n",
    "    \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    edited_responses_df.drop_duplicates(subset=[std_idcs['email_idx']], keep='last')\n",
    "    \n",
    "    return edited_responses_df\n",
    "\n",
    "\n",
    "def flag_duplicates(responses_df):\n",
    "    \"\"\"\n",
    "    flags duplicated rows (responses) based on 'Email address' and keeps the last response submitted.\n",
    "    Note: Some students may make changes to their responses and submit a new one,\n",
    "    this's why this function keeps the last response submitted and flag preceding ones, and leaves a note.\n",
    "    \n",
    "    TODO: Check with the organizers what else is an adequate action.\n",
    "    \n",
    "    params :\n",
    "        response_df: the responses data (DataFrame)\n",
    "    returns:\n",
    "        edited_responses_df: An edited responses_df with 'flag' column updated\n",
    "    \"\"\"\n",
    "    \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    # Format: df['col'] = (value_if_false).where(condition, value_if_true)\n",
    "    \n",
    "    edited_responses_df[std_idcs['flag_idx']] = (edited_responses_df[std_idcs['flag_idx']]).where(\n",
    "        # True/False nupmy array - True: duplicated, False: unique (before inversion)\n",
    "        np.invert(np.array(edited_responses_df.duplicated(subset=[1], keep='last'))),\n",
    "        \"flagged\"\n",
    "    )\n",
    "\n",
    "    edited_responses_df[std_idcs['notes_idx']] = (edited_responses_df[std_idcs['notes_idx']]).where(\n",
    "        # True/False nupmy array - True: duplicated, False: unique (before inversion)\n",
    "        np.invert(np.array(edited_responses_df.duplicated(subset=[1], keep='last'))),\n",
    "        \"A duplicated response\"\n",
    "    )\n",
    "    \n",
    "    return edited_responses_df\n",
    "\n",
    "\n",
    "def flag_duplicate_refs(ref_responses_df):\n",
    "    \"\"\"\n",
    "    flags duplicated reference responces (i.e. submitting multiple letters), and keep the last submitted one.\n",
    "    \n",
    "    TODO: Check with the organizers what else is an adequate action.\n",
    "    \n",
    "    params :\n",
    "        ref_response_df: the responses data (DataFrame)\n",
    "    returns:\n",
    "        edited_ref_responses_df: An edited responses_df with 'flag' column updated\n",
    "    \"\"\"\n",
    "    \n",
    "    edited_ref_responses_df = ref_responses_df.copy()\n",
    "    \n",
    "    # Format: df['col'] = (value_if_false).where(condition, value_if_true)\n",
    "    \n",
    "    edited_ref_responses_df[ref_idcs['flag_idx']] = (edited_ref_responses_df[ref_idcs['flag_idx']]).where(\n",
    "        # True/False nupmy array - True: duplicated, False: unique (before inversion)\n",
    "        np.invert(np.array(edited_ref_responses_df.duplicated(subset=[ref_idcs['email_idx'], ref_idcs['std']['email_idx']], keep='last'))),\n",
    "        \"flagged\"\n",
    "    )\n",
    "\n",
    "    edited_ref_responses_df[ref_idcs['notes_idx']] = (edited_ref_responses_df[ref_idcs['notes_idx']]).where(\n",
    "        # True/False nupmy array - True: duplicated, False: unique (before inversion)\n",
    "        np.invert(np.array(edited_ref_responses_df.duplicated(subset=[ref_idcs['email_idx'], ref_idcs['std']['email_idx']], keep='last'))),\n",
    "        \"Submitted more than one letter for the same student\"\n",
    "    )\n",
    "    \n",
    "    return edited_ref_responses_df\n",
    "\n",
    "\n",
    "def flag_short(responses_df, essay_qs):\n",
    "    \"\"\"\n",
    "    flags insufficently short answers (less than a specific lower limit) for a specified\n",
    "    set of essay questions, and leaves a note.\n",
    "    \n",
    "    params :\n",
    "        response_df: the responses data (DataFrame)\n",
    "        essay_qs   : essay questions (list)\n",
    "    returns:\n",
    "        edited_responses_df: An edited responses_df with short answers flagged\n",
    "    \"\"\"\n",
    "    \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    # Go through all the responses and for each response go through the answers for the essay questions\n",
    "    for row_index in range(len(edited_responses_df)):\n",
    "        for question in essay_qs:\n",
    "            \n",
    "            if word_count(str(edited_responses_df.iloc[row_index, question])) < MIN_WORDS_NUM:\n",
    "                edited_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "                \n",
    "                edited_responses_df = leave_note(edited_responses_df, row_index, \"Insufficient short answer/s\")        \n",
    "                    \n",
    "    return edited_responses_df\n",
    "                    \n",
    "\n",
    "# Should we flag long answers ??\n",
    "def flag_long(responses_df, essay_qs):\n",
    "    \"\"\"\n",
    "    flags extremely long answers (more than a specific upprt limit) for a specified\n",
    "    set of essay questions, and leaves a note.\n",
    "    \n",
    "    params :\n",
    "        response_df: the responses data (DataFrame)\n",
    "        essay_qs   : essay questions (list)\n",
    "    returns:\n",
    "        edited_response_df: An edited responses_df with long answers flagged\n",
    "    \"\"\"\n",
    "     \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    # Go through all the responses and for each response go through the answers for the essay questions\n",
    "    for row_index in range(len(edited_responses_df)):\n",
    "        for question in essay_qs:\n",
    "            \n",
    "            if word_count(str(edited_responses_df.iloc[row_index, question])) > MAX_WORDS_NUM:\n",
    "                edited_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "                \n",
    "                edited_responses_df = leave_note(edited_responses_df, row_index, \"Extremely long answer/s\")\n",
    "                        \n",
    "    return edited_responses_df\n",
    "\n",
    "\n",
    "def match_refs_based_on_stdn_email(std_responses_df, ref_responses_df):\n",
    "    \"\"\"\n",
    "    Matches references with the student/s they are supporting, and flags student response if they get less than the required\n",
    "    number of reference letters, and leaves a note.\n",
    "    \n",
    "    params :\n",
    "        std_responses_df : students responses data (DataFrame)\n",
    "        ref_responses_df : references responses data (DataFrame)\n",
    "    returns:\n",
    "        edited_std_responses_df: An edited std_responses_df with answers with unsatisfied conditions for recommendation letters flagged\n",
    "        ref_responses_df: The ref_responses_df but with marking the \"Matched\" column for letters those successfully matched.\n",
    "    \"\"\"\n",
    "     \n",
    "    ref_responses_df = flag_duplicate_refs(ref_responses_df)\n",
    "    edited_std_responses_df = std_responses_df.copy()\n",
    "    \n",
    "    for row_index in range(len(edited_std_responses_df)):\n",
    "        \n",
    "        if edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] is not None and edited_std_responses_df.iloc[row_index, std_idcs['second_recomm_letter_idx']] is not None:\n",
    "            continue\n",
    "            \n",
    "        # Flag student response if BOTH of their references didn't submit any letter\n",
    "        \n",
    "        if edited_std_responses_df.iloc[row_index, std_idcs['email_idx']] not in ref_responses_df[ref_idcs['std']['email_idx']].values:\n",
    "            \n",
    "            edited_std_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "            edited_std_responses_df = leave_note(edited_std_responses_df, row_index, \"Got no recommendation letters\")\n",
    "        \n",
    "        # Flag student response if ANY of their references didn't submit any letter\n",
    "        # Assign the one submitted letters to that student\n",
    "        \n",
    "        elif ref_responses_df[ref_idcs['std']['email_idx']].value_counts()[edited_std_responses_df.iloc[row_index, std_idcs['email_idx']]] == 1:\n",
    "            \n",
    "            edited_std_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "            edited_std_responses_df = leave_note(edited_std_responses_df, row_index, \"Got only one recommendation letter\")\n",
    "            \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, ref_idcs['std']['email_idx']] == edited_std_responses_df.iloc[row_index, std_idcs['email_idx']]:\n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "        \n",
    "        # This, from here below, would look much prettier with a while loop!\n",
    "    \n",
    "        # If BOTH references subnitted ONLY ONE letter,\n",
    "        # Assign the right two letters to the specific student\n",
    "        \n",
    "        elif ref_responses_df[ref_idcs['std']['email_idx']].value_counts()[edited_std_responses_df.iloc[row_index, std_idcs['email_idx']]] == 2:\n",
    "            \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, ref_idcs['std']['email_idx']] == edited_std_responses_df.iloc[row_index, std_idcs['email_idx']]:\n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "                    \n",
    "                    break\n",
    "                \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, ref_idcs['std']['email_idx']] == edited_std_responses_df.iloc[row_index, std_idcs['email_idx']] and edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] is not None:\n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['second_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "        \n",
    "        # Flag student response if one of or both their references submitted MORE THAN ONE letter\n",
    "        # And assign the right two letters to that student\n",
    "        \n",
    "        elif ref_responses_df[ref_idcs['std']['email_idx']].value_counts()[edited_std_responses_df.iloc[row_index, std_idcs['email_idx']]] > 2:\n",
    "            \n",
    "            #edited_std_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "            edited_std_responses_df = leave_note(edited_std_responses_df, row_index,\n",
    "                                                 \"Some reference/s submitted more than two letters (The last was taken)\")\n",
    "            \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, ref_idcs['std']['email_idx']] == edited_std_responses_df.iloc[row_index, std_idcs['email_idx']] and ref_responses_df.iloc[ref_index, ref_idcs['flag_idx']] is None:\n",
    "                    \n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, ref_idcs['std']['email_idx']] == edited_std_responses_df.iloc[row_index, std_idcs['email_idx']] and edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] is not None and ref_responses_df.iloc[ref_index, ref_idcs['flag_idx']] is None:\n",
    "                    \n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['second_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "                    \n",
    "    return edited_std_responses_df, ref_responses_df\n",
    "\n",
    "\n",
    "def match_refs_based_on_stdn_name(std_responses_df, ref_responses_df):\n",
    "    \"\"\"\n",
    "    Matches references with the student/s they are supporting, and flags student response if they get less than the required\n",
    "    number of reference letters, and leaves a note.\n",
    "    \n",
    "    params :\n",
    "        std_responses_df : students responses data (DataFrame)\n",
    "        ref_responses_df : references responses data (DataFrame)\n",
    "    returns:\n",
    "        edited_std_responses_df: An edited std_responses_df with answers with unsatisfied conditions for recommendation letters flagged,\n",
    "        ref_responses_df: The ref_responses_df but with marking the \"Matched\" column for letters those successfully matched.\n",
    "    \"\"\"\n",
    "     \n",
    "    ref_responses_df = flag_duplicate_refs(ref_responses_df)\n",
    "    edited_std_responses_df = std_responses_df.copy()\n",
    "    \n",
    "    for row_index in range(len(edited_std_responses_df)):\n",
    "        \n",
    "        if edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] is not None and edited_std_responses_df.iloc[row_index, std_idcs['second_recomm_letter_idx']] is not None:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            got_one_letter = ref_responses_df[[ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]].value_counts()[tuple(edited_std_responses_df.iloc[row_index, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1])] == 1\n",
    "        \n",
    "        except KeyError:\n",
    "            got_one_letter = False\n",
    "            \n",
    "        try:\n",
    "            got_two_letters = ref_responses_df[[ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]].value_counts()[tuple(edited_std_responses_df.iloc[row_index, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1])] == 2\n",
    "\n",
    "        except KeyError:\n",
    "            got_two_letters = False \n",
    "            \n",
    "        try:\n",
    "            got_more_than_two_letters = ref_responses_df[[ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]].value_counts()[tuple(edited_std_responses_df.iloc[row_index, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1])] > 2\n",
    "       \n",
    "        except KeyError:\n",
    "            got_more_than_two_letters = False \n",
    "        \n",
    "        if not got_one_letter and not got_two_letters and not got_more_than_two_letters:\n",
    "            got_no_letters = True\n",
    "            \n",
    "        else:\n",
    "            got_no_letters = False\n",
    "    \n",
    "        # Flag student response if BOTH of their references didn't submit any letter\n",
    "          \n",
    "        if got_no_letters:\n",
    "            \n",
    "            edited_std_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "            edited_std_responses_df = leave_note(edited_std_responses_df, row_index, \"Got no recommendation letters\")\n",
    "        \n",
    "        # Flag student response if ANY of their references didn't submit any letter\n",
    "        # Assign the one submitted letters to that student\n",
    "            \n",
    "        if got_one_letter:\n",
    "            \n",
    "            edited_std_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "            edited_std_responses_df = leave_note(edited_std_responses_df, row_index, \"Got only one recommendation letter\")\n",
    "            \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, [ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]].tolist() == edited_std_responses_df.iloc[row_index, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1].tolist():\n",
    "                    \n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "                    \n",
    "                    break\n",
    "        \n",
    "        # This, from here below, would look much prettier with a while loop!\n",
    "    \n",
    "        # If BOTH references subnitted ONLY ONE letter,\n",
    "        # Assign the right two letters to the specific student\n",
    "        \n",
    "        if got_two_letters:\n",
    "            \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, [ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]].tolist() == edited_std_responses_df.iloc[row_index, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1].tolist():\n",
    "                    \n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "                    \n",
    "                    break\n",
    "                \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, [ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]].tolist() == edited_std_responses_df.iloc[row_index, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1].tolist() and edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] is not None:\n",
    "                    \n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['second_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "        \n",
    "        # Check if there are references who submitted MORE THAN ONE letter to the same student\n",
    "        # And assign the right two letters to that student\n",
    "        \n",
    "        if got_more_than_two_letters:\n",
    "            \n",
    "            edited_std_responses_df = leave_note(edited_std_responses_df, row_index,\n",
    "                                                 \"Some reference/s submitted more than two letters (The last was taken)\")\n",
    "\n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "\n",
    "                if ref_responses_df.iloc[ref_index, [ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]].tolist() == edited_std_responses_df.iloc[row_index, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1].tolist() and ref_responses_df.iloc[ref_index, ref_idcs['flag_idx']] is None:\n",
    "\n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "\n",
    "                    break\n",
    "\n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "\n",
    "                if ref_responses_df.iloc[ref_index, [ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]].tolist() == edited_std_responses_df.iloc[row_index, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1].tolist() and edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] is not None and ref_responses_df.iloc[ref_index, ref_idcs['flag_idx']] is None:\n",
    "\n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['second_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "                    \n",
    "    return edited_std_responses_df, ref_responses_df\n",
    "\n",
    "\n",
    "def match_references(std_responses_df, ref_responses_df):\n",
    "    \n",
    "    edited_std_responses_df, ref_responses_df = match_refs_based_on_stdn_email(std_responses_df, ref_responses_df)\n",
    "    #edited_std_responses_df, ref_responses_df = match_refs_based_on_stdn_name(std_responses_df, ref_responses_df)\n",
    "    \n",
    "    return edited_std_responses_df, ref_responses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b1027-0f5f-49fc-a338-3127be316a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(std_responses_df, ref_responses_df):\n",
    "    \n",
    "    std_responses_df = column_names_to_indices(std_responses_df, std_questions_dict)\n",
    "    ref_responses_df = column_names_to_indices(ref_responses_df, ref_questions_dict)\n",
    "    \n",
    "    responses_df_flagged_duplicates = flag_duplicates(std_responses_df)\n",
    "    responses_df_flagged_short = flag_short(responses_df_flagged_duplicates, essay_qs)\n",
    "    responses_df_flagged_long = flag_long (responses_df_flagged_short, essay_qs)\n",
    "    \n",
    "    responses_df_spaces_removed, ref_responses_df_lowercase = remove_spaces(responses_df_flagged_long, std_str_qs, ref_responses_df, ref_str_qs)\n",
    "    \n",
    "    responses_df_lowercase, ref_responses_df_lowercase = to_lowercase(responses_df_spaces_removed, std_str_qs, ref_responses_df, ref_str_qs)\n",
    "    responses_df_matched, ref_responses_df_matched = match_references(responses_df_lowercase, ref_responses_df_lowercase)\n",
    "    responses_df_final, ref_responses_df_final = to_uppercase(responses_df_matched, std_str_qs, ref_responses_df_matched, ref_str_qs)\n",
    "    \n",
    "    ref_responses_df_unmatched = get_unmatched_letters(ref_responses_df_final)\n",
    "    \n",
    "    # Putting back original column names, and saving the Excel file\n",
    "    named_responses_df_final = indices_to_column_names(responses_df_final, std_questions_dict)\n",
    "    named_responses_df_final.to_excel(RESULTS_FOLDER_NAME + \"/filtered_responses_with_flagged.xlsx\")\n",
    "    \n",
    "    responses_df_final_flagged_removed = remove_flagged(responses_df_final)\n",
    "    \n",
    "    # Putting back original column names, and saving the Excel file\n",
    "    named_responses_df_final_flagged_removed = indices_to_column_names(responses_df_final_flagged_removed, std_questions_dict)\n",
    "    named_responses_df_final_flagged_removed.to_excel(RESULTS_FOLDER_NAME + \"/filtered_responses_with_flagged_removed.xlsx\")\n",
    "    \n",
    "    # Putting back original column names, and saving the Excel file\n",
    "    named_ref_responses_df_final = indices_to_column_names(ref_responses_df_final, ref_questions_dict)\n",
    "    named_ref_responses_df_final.to_excel(RESULTS_FOLDER_NAME + \"/ref_responses_with_flagged.xlsx\")\n",
    "    \n",
    "    return responses_df_final, responses_df_final_flagged_removed, ref_responses_df_final, ref_responses_df_unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617af5db-1174-4c1f-a02a-df41298e2195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses_df_final, responses_df_final_flagged_removed, ref_responses_df_final, ref_responses_df_unmatched = main(std_raw_responses_df, ref_raw_responses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bbaf72-f2bf-4bfb-bf5e-5e0da485a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df_final.iloc[:, std_idcs['flag_idx']:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d567c99-fefc-435e-9701-866ad1159c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df_final.iloc[:, std_idcs['email_idx']:std_idcs['email_idx'] + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1094274-d043-482d-a4b0-cc6e32c75654",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df_final.iloc[:, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d36edf2-8ddd-4a19-8e19-44ba2b93fb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_responses_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c53cea-f6e7-4898-a6ab-02d5077133fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_responses_df_unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175baf01-4029-44a3-8a40-a3be55f43bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df_final_flagged_removed.iloc[:, std_idcs['flag_idx']:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c5b21-3a10-4ab3-a2f6-eddae7c68532",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df_final_flagged_removed.iloc[:, std_idcs['email_idx']:std_idcs['email_idx'] + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686c60be-c671-4589-90c4-691e3c4b9634",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df_final_flagged_removed.iloc[:, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db9c47-9fec-4ae3-aa21-e6ef37cc5078",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_responses_df_final.groupby([ref_idcs['std']['email_idx']]).size().reset_index().rename(columns={0: 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc70e73a-f029-42ce-b6df-ad35a6cbb12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_responses_df_final.groupby([ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]).size().reset_index().rename(columns={0: 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd83e5-0652-4cae-aa3e-0725bce6b986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
