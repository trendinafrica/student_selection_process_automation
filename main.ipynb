{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86648c93-943b-4148-be8c-b86c23072b5a",
   "metadata": {},
   "source": [
    "# Applications processing Automation\n",
    "\n",
    "The purpose of this code is to automate the first trivial filtering steps in the processing of the applications for the TReND in Africa Computational Neuroscience and Machine Learning Basics course.\n",
    "\n",
    "This code is organized as a set of functions to be applied as a processing pipeline on the application responses data (See [documentation](https://docs.google.com/document/d/1n4pMEOgMuenuFpN6zXQtZlpYFXwPat2P4-SzZaN8mFg/edit?usp=drivesdk)).\n",
    "\n",
    "### **How to use (as a developer):**\n",
    "Just clone the Github repository and get into the business!\\\n",
    "If you have anaconda and yupyter installed locally you can just clone the repory directly on your machine. Elsewise, you can clone it into Google Colab.\n",
    "(In either case, don't forget to regularly pull and push changes).\n",
    "\n",
    "### **How to use (as a reviewer):**\n",
    "If you are on Github now, open this notebook in Google Colab, or clone the whole repo locally, so you can run the cells. In case of running it in Colab, don't forget to save and download the resulting Excel sheet of the processed responses into a local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "id": "d5561a65-902a-424b-bc94-4b417849e29e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "id": "8b154dc7-4f8f-4d8f-8417-5108fb288621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp', 'Email address', 'First Name', 'Last Name', 'Unnamed: 4',\n",
       "       'Unnamed: 5', 'Unnamed: 6', 'Career Stage',\n",
       "       'Name of current University or Research Institution',\n",
       "       'Undergraduate degree (completed or ongoing, eg. Neuroscience, Mathematics)',\n",
       "       'Master's degree (completed or ongoing, if applicable, eg. Neuroscience, Mathematics)',\n",
       "       'PhD degree (completed or ongoing, if applicable, eg. Neuroscience, Mathematics)',\n",
       "       'Current research focus or research focus of the last research project you were engaged in (if applicable)',\n",
       "       'Why would you like to attend the course? (2000 characters max)',\n",
       "       'How do you think you could contribute to the course?  (2000 characters max)',\n",
       "       'At the end of the first week the students will start a short individual research project. What would be your dream project?  (2000 characters max)',\n",
       "       'Please attach a 1-page CV in pdf format (documents longer than one page will be discarded). If you have trouble attaching the file, please send it to compneuroai@trendinafrica.org with the name name_surname_CV.pdf',\n",
       "       'Evaluation of Students', 'flag', 'notes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 879,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that you have to download the responses data Excel sheet from Google Drive and put it in the same folder as the code.\n",
    "# You don't have to do this if you cloned the Github repo (all will be organized in the repo).\n",
    "\n",
    "# TODO: Load data directly from Google Drive.\n",
    "\n",
    "#DATA_DIR = './Copy of Answers_Application_form_TReND_Comp_Neuro_FIRSTPASS.xlsx'\n",
    "DATA_DIR = './dummy_responses_data.xlsx'\n",
    "\n",
    "raw_responses_df = pd.read_excel(DATA_DIR)\n",
    "\n",
    "# Adding two columns to the responses DataFrame (initialized with None for all cells).\n",
    "raw_responses_df['flag'] = None  #String (\"flagged\" or None)\n",
    "raw_responses_df['notes'] = None #String (Text of notes == reasaons for flagging)\n",
    "\n",
    "raw_responses_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "id": "ef57ab8a-3870-4752-9ab7-edb7c6dce504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Timestamp',\n",
       " 1: 'Email address',\n",
       " 2: 'First Name',\n",
       " 3: 'Last Name',\n",
       " 4: 'Unnamed: 4',\n",
       " 5: 'Unnamed: 5',\n",
       " 6: 'Unnamed: 6',\n",
       " 7: 'Career Stage',\n",
       " 8: 'Name of current University or Research Institution',\n",
       " 9: 'Undergraduate degree (completed or ongoing, eg. Neuroscience, Mathematics)',\n",
       " 10: \"Master's degree (completed or ongoing, if applicable, eg. Neuroscience, Mathematics)\",\n",
       " 11: 'PhD degree (completed or ongoing, if applicable, eg. Neuroscience, Mathematics)',\n",
       " 12: 'Current research focus or research focus of the last research project you were engaged in (if applicable)',\n",
       " 13: 'Why would you like to attend the course? (2000 characters max)',\n",
       " 14: 'How do you think you could contribute to the course?  (2000 characters max)',\n",
       " 15: 'At the end of the first week the students will start a short individual research project. What would be your dream project?  (2000 characters max)',\n",
       " 16: 'Please attach a 1-page CV in pdf format (documents longer than one page will be discarded). If you have trouble attaching the file, please send it to compneuroai@trendinafrica.org with the name name_surname_CV.pdf',\n",
       " 17: 'Evaluation of Students',\n",
       " 18: 'flag',\n",
       " 19: 'notes'}"
      ]
     },
     "execution_count": 880,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this dictionary as a reference for column names.\n",
    "\n",
    "questions_dic = {i: column for i, column in enumerate(raw_responses_df.columns)}\n",
    "questions_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "id": "7c1e45a6-24aa-461b-b653-cab3d48737cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], dtype='int64')"
      ]
     },
     "execution_count": 881,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replpace column names with indices.\n",
    "\n",
    "responses_df = raw_responses_df.rename(columns={column: i for i, column in enumerate(questions_dic.values())})\n",
    "responses_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "id": "9765daba-961b-4024-bced-95847f8cd825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carefully specify names of the columns to be processed (mostly responses for essay questions).\n",
    "\n",
    "# TODO: To avoid any naming mistakes, replace questions, as columns names, with a key (or simply, indices).\n",
    "\n",
    "essay_qs = [13, 14, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "id": "c098d061-c2d2-41e7-8ae9-fc7f8f640ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the minimum and maximun number of words for ansewrs for essay questions.\n",
    "# Note: These parameters apply for for all essay questions.\n",
    "\n",
    "MIN_WORDS_NUM = 50\n",
    "MAX_WORDS_NUM = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44138fe5-309e-4f87-ad94-532b52df55d3",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "id": "9eb2db56-8054-4e0f-9ec9-0748f2937a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(answer):\n",
    "    \"\"\"\n",
    "    Takes a specific answer (cell) of a specific essay question and returns the answer's number of words.\n",
    "    \"\"\"\n",
    "    \n",
    "    return len(answer.split())\n",
    "\n",
    "\n",
    "def set_flag(responses_df, email):\n",
    "    \"\"\"\n",
    "    Set the 'flag' column value to \"flagged\" for a response chosen by it's 'Email address'\n",
    "    \"\"\"\n",
    "    \n",
    "    # This modifies the DataFrame itself (i.e change in place)\n",
    "    # # 1 - 'Email address' column, 18 = 'flag' column\n",
    "    responses_df.iloc[responses_df[1] == email, 18] = \"flagged\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a1215f-aea3-47ee-a4e2-a91410822c4a",
   "metadata": {},
   "source": [
    "## Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "id": "b93f7967-a7e6-47a4-a80c-aa765259dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(responses_df):\n",
    "    \"\"\"\n",
    "    removes duplicated rows (responses) based on 'Email address' and keeps the last response submitted.\n",
    "    Note: Some students may make changes to their responses and submit a new one,\n",
    "    this's why this function keeps the last response submitted and removes preceding ones.\n",
    "    \n",
    "    TODO: Check with the organizers what else is an adequate action.\n",
    "    \n",
    "    params :\n",
    "        response_df: the responses data (DataFrame)\n",
    "    returns:\n",
    "        edited_responses_df: An edited response_df with duplicates removed\n",
    "    \"\"\"\n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    # 1 - 'Email address' column\n",
    "    edited_responses_df.drop_duplicates(subset=[1], keep='last')\n",
    "    \n",
    "    return edited_responses_df\n",
    "\n",
    "\n",
    "def flag_duplicates(responses_df):\n",
    "    \"\"\"\n",
    "    flags duplicated rows (responses) based on 'Email address' and keeps the last response submitted.\n",
    "    Note: Some students may make changes to their responses and submit a new one,\n",
    "    this's why this function keeps the last response submitted and removes preceding ones.\n",
    "    \n",
    "    TODO: Check with the organizers what else is an adequate action.\n",
    "    \n",
    "    params :\n",
    "        response_df: the responses data (DataFrame)\n",
    "    returns:\n",
    "        edited_responses_df: An edited responses_df with 'flag' column updated\n",
    "    \"\"\"\n",
    "    \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    # True/False nupmy array (True: duplicated, False: unique)\n",
    "    is_duplicate = np.rot90(\n",
    "            np.squeeze(\n",
    "                np.array(\n",
    "                    [[edited_responses_df.duplicated(subset=[1], keep='last')],\n",
    "                     [edited_responses_df.duplicated(subset=[1], keep='last')]]\n",
    "                )))\n",
    "    \n",
    "    # Format: df['col'] = (value_if_false).where(condition, value_if_true)\n",
    "    \n",
    "    # 18 = 'flag' column, 19 = 'notes' column\n",
    "    edited_responses_df[18] = (edited_responses_df[18]).where(\n",
    "        # True/False nupmy array - True: duplicated, False: unique (before inversion)\n",
    "        np.invert(np.array(edited_responses_df.duplicated(subset=[1], keep='last'))),\n",
    "        \"flagged\"\n",
    "    )\n",
    "    # 18 = 'flag' column, 19 = 'notes' column\n",
    "    edited_responses_df[19] = (edited_responses_df[19]).where(\n",
    "        # True/False nupmy array - True: duplicated, False: unique (before inversion)\n",
    "        np.invert(np.array(edited_responses_df.duplicated(subset=[1], keep='last'))),\n",
    "        \"A duplicated response\"\n",
    "    )\n",
    "    \n",
    "    return edited_responses_df\n",
    "\n",
    "\n",
    "def flag_short(responses_df, essay_qs):\n",
    "    \"\"\"\n",
    "    flags insufficently short answers (less than a specific lower limit) for a specified\n",
    "    set of essay questions.\n",
    "    \n",
    "    params :\n",
    "        response_df: the responses data (DataFrame)\n",
    "        essay_qs   : essay questions (list)\n",
    "    returns:\n",
    "        edited_responses_df: An edited responses_df with short answers removed\n",
    "    \"\"\"\n",
    "    \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    # Go through all the responses and for each response go through the answers for the essay questions\n",
    "    for row_index in range(len(edited_responses_df)):\n",
    "        for question in essay_qs:\n",
    "            \n",
    "            if word_count(str(edited_responses_df.iloc[row_index, question])) < MIN_WORDS_NUM:\n",
    "                edited_responses_df.iloc[row_index, 18] = \"flagged\"\n",
    "                \n",
    "                if \"Insufficient short answer/s\" not in str(edited_responses_df.iloc[row_index, 19]):\n",
    "                    if edited_responses_df.iloc[row_index, 19] is None:\n",
    "                        edited_responses_df.iloc[row_index, 19] = \"Insufficient short answer/s\"\n",
    "                    else:\n",
    "                        edited_responses_df.iloc[row_index, 19] = str(edited_responses_df.iloc[row_index, 19]) + \" - \" + \"Insufficient short answer/s\" + \" - \"            \n",
    "                    \n",
    "    return edited_responses_df\n",
    "                    \n",
    "\n",
    "# Should we flag long answers ??\n",
    "def flag_long(responses_df, essay_qs):\n",
    "    \"\"\"\n",
    "    flags extremely long answers (more than a specific upprt limit) for a specified\n",
    "    set of essay questions.\n",
    "    \n",
    "    params :\n",
    "        response_df: the responses data (DataFrame)\n",
    "        essay_qs   : essay questions (list)\n",
    "    returns:\n",
    "        edited_response_df: An edited responses_df with long answers removed\n",
    "    \"\"\"\n",
    "     \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    # Go through all the responses and for each response go through the answers for the essay questions\n",
    "    for row_index in range(len(edited_responses_df)):\n",
    "        for question in essay_qs:\n",
    "            \n",
    "            if word_count(str(edited_responses_df.iloc[row_index, question])) > MAX_WORDS_NUM:\n",
    "                edited_responses_df.iloc[row_index, 18] = \"flagged\"\n",
    "                \n",
    "                if \"Extremely long answer/s\" not in str(edited_responses_df.iloc[row_index, 19]):\n",
    "                    if edited_responses_df.iloc[row_index, 19] is None:\n",
    "                        edited_responses_df.iloc[row_index, 19] = \"Extremely long answer/s\"\n",
    "                    else:\n",
    "                        edited_responses_df.iloc[row_index, 19] = str(edited_responses_df.iloc[row_index, 19]) + \" - \" + \"Extremely long answer/s\" + \" - \"\n",
    "                        \n",
    "    return edited_responses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "id": "e80b1027-0f5f-49fc-a338-3127be316a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(responses_df):\n",
    "    \n",
    "    responses_df_flagged_duplicates = flag_duplicates(responses_df)\n",
    "    responses_df_flagged_short = flag_short(responses_df_flagged_duplicates, essay_qs)\n",
    "    responses_df_final = flag_long (responses_df_flagged_short, essay_qs)\n",
    "    \n",
    "    return responses_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "617af5db-1174-4c1f-a02a-df41298e2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_responses_df = main(responses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "id": "6ccc7b34-38b0-4dd6-8415-2e3e1900ad51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
