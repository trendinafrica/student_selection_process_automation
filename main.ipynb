{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86648c93-943b-4148-be8c-b86c23072b5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Applications Processing Automation\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/trendinafrica/student_selection_process_automation/blob/main/main.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "(*By: [@mahmoud-elmakki](https://github.com/mahmoud-elmakki)*)\n",
    "\n",
    "The purpose of this code is to automate the first trivial filtering steps in the processing of the applications for the TReND in Africa Computational Neuroscience and Machine Learning Basics course.\n",
    "\n",
    "This code is organized as a set of functions to be applied as a processing pipeline on the application responses data (See [documentation](https://docs.google.com/document/d/1n4pMEOgMuenuFpN6zXQtZlpYFXwPat2P4-SzZaN8mFg/edit?usp=drivesdk)).\n",
    "\n",
    "Also see [weighted_grading_first_round.ipynb](https://github.com/trendinafrica/student_selection_process_automation/blob/main/weighted_grading_first_round.ipynb), and [weighted_grading_second_round.ipynb](https://github.com/trendinafrica/student_selection_process_automation/blob/main/weighted_grading_second_round.ipynb).\n",
    "\n",
    "### **How to use (as a developer):**\n",
    "Just clone the Github repository and get into the business!\\\n",
    "If you have anaconda and yupyter installed locally you can just clone the repory directly on your machine. Elsewise, you can clone it into Google Colab.\n",
    "(In either case, if you have any valuable contributions, don't hesitatte to do a Pull Request).\n",
    "\n",
    "### **How to use (as a reviewer):**\n",
    "If you are on Github now, open this notebook in Google Colab, or clone the whole repo locally, so you can run the cells. In case of running it in Colab, don't forget to save and download the resulting Excel sheet of the processed responses into a local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5561a65-902a-424b-bc94-4b417849e29e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d1cadd-48d2-4d69-89a6-d73df5e63ed3",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b154dc7-4f8f-4d8f-8417-5108fb288621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that you have to download the responses data Excel sheet from Google Drive and put it in the same folder as the code.\n",
    "# You don't have to do this if you cloned the Github repo (all will be organized in the repo).\n",
    " \n",
    "# TODO: Load data directly from Google Drive.\n",
    "\n",
    "# Loading students responses data\n",
    "STD_DATA_DIR = './responses_data/TReND Comp Neuro application form Rwanda 2024 (Responses).xlsx'\n",
    "std_raw_responses_df = pd.read_excel(STD_DATA_DIR)\n",
    "\n",
    "# Loading references responses data\n",
    "REF_DATA_DIR = './responses_data/Recommendation Letter Portal (Responses).xlsx'\n",
    "ref_raw_responses_df = pd.read_excel(REF_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28df2d3-6e05-4bb4-b55a-328628375d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(std_raw_responses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f6a16-48f4-4107-84ab-b0b949da26d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ref_raw_responses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48735f08-d18e-4271-a98c-839614f349c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just specify folder names - thje code will create the directory\n",
    "\n",
    "RESULTS_FOLDER_NAME = \"filtered_responses\"\n",
    "RESULTS_DIR = os.path.join(os.getcwd(), RESULTS_FOLDER_NAME)\n",
    "\n",
    "if not os.path.exists(RESULTS_DIR):\n",
    "    os.mkdir(RESULTS_DIR)\n",
    "    \n",
    "    \n",
    "LETTERS_STATS_FOLDER_NAME = \"letters_stats\"\n",
    "LETTERS_STATS_DIR = os.path.join(os.getcwd(), LETTERS_STATS_FOLDER_NAME)\n",
    "\n",
    "if not os.path.exists(LETTERS_STATS_DIR):\n",
    "    os.mkdir(LETTERS_STATS_DIR)\n",
    "    \n",
    "    \n",
    "FLAGGED_STATS_FOLDER_NAME = \"flagged_stats\"\n",
    "FLAGGED_STATS_DIR = os.path.join(os.getcwd(), FLAGGED_STATS_FOLDER_NAME)\n",
    "\n",
    "if not os.path.exists(FLAGGED_STATS_DIR):\n",
    "    os.mkdir(FLAGGED_STATS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c86c5-e690-464e-a42d-3a9a501bcc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns added to the student responses DataFrame (initialized with None for all cells).\n",
    "std_raw_responses_df['Flag'] = None  #String (\"flagged\" or None)\n",
    "std_raw_responses_df['Notes'] = None #String (Text of notes == reasaons for flagging)\n",
    "std_raw_responses_df['Recommendation Letter 1'] = None\n",
    "std_raw_responses_df['Recommendation Letter 2'] = None\n",
    "\n",
    "# Columns added to the referee responses DataFrame.\n",
    "ref_raw_responses_df['Flag'] = None\n",
    "ref_raw_responses_df['Notes'] = None\n",
    "ref_raw_responses_df['Matched'] = \"unmatched\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cd2c68-63d1-4345-8c4c-ba0abdb53a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_columns = std_raw_responses_df.columns\n",
    "ref_columns = ref_raw_responses_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a636f98c-7517-485c-a018-0c1113047412",
   "metadata": {},
   "source": [
    "## configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb241b1a-36d9-4e70-bc60-2621fce3c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the minimum and maximun number of words for ansewrs for essay questions.\n",
    "# Note: These parameters apply for for all essay questions\n",
    "\n",
    "MIN_WORDS_NUM = 50\n",
    "MAX_WORDS_NUM = 350\n",
    "\n",
    "# To check if the recommendation letter was submitted by an institutional email, or not.\n",
    "UNOFFICIAL_EMAILS = [\"gmail\", \"yahoo\", \"hotmail\"]\n",
    "\n",
    "# Flag, or not flag, students who got one recommendation letter.\n",
    "FLAG_ONE_LETTER = False\n",
    "\n",
    "FLAG_NON_AFRICANS = False\n",
    "FLAG_TRAVELLING_ABROAD = True\n",
    "\n",
    "FLAG_NA = True\n",
    "\n",
    "# Countries to accept people from:\n",
    "african_countries = ['Algeria', 'Angola', 'Benin', 'Botswana', 'Burkina Faso', 'Burundi', 'Cabo Verde', 'Cameroon', 'Central African Republic', 'Chad', 'Comoros', 'Djibouti', 'Democratic Republic of the Congo', 'Egypt', 'Equatorial Guinea', 'Eritrea', 'Eswatini', 'Ethiopia', 'Gabon', 'Gambia', 'Ghana', 'Guinea', 'Guinea-Bissau', \"Ivory Coast (CÃ´te d'Ivoire)\", 'Kenya', 'Lesotho', 'Liberia', 'Libya', 'Madagascar', 'Malawi', 'Mali', 'Mauritania', 'Mauritius', 'Morocco', 'Mozambique', 'Namibia', 'Niger', 'Nigeria', 'Republic of the Congo', 'Rwanda', 'Sao Tome & Principe', 'Senegal', 'Seychelles', 'Sierra Leone', 'Somalia', 'South Africa', 'South Sudan', 'Sudan', 'Tanzania', 'Togo', 'Tunisia', 'Uganda', 'Zambia', 'Zimbabwe']\n",
    "\n",
    "notes_dict = {\n",
    "    \n",
    "    'std' : {\n",
    "        'long_ans' : \"Extremely long answer/s\",\n",
    "        'short_ans' : \"Insufficiently short answer/s\",\n",
    "        'got_no_letters' : \"Got no recommendation letters\",\n",
    "        'got_one_letter' : \"Got only one recommendation letter\",\n",
    "        'duplicate' : \"A duplicated response\",\n",
    "        'traveling_abroad' : \"Traveling from outside Africa\",\n",
    "        'non_african' : \"Non-african\",\n",
    "        'no_cv' : \"Didn't upload a CV\",\n",
    "        'non_institutional_ref_email' : \"Submitted a non-institutional email address for one of or both of their referees\",\n",
    "        'duplicate_letters' : \"Some reference/s submitted more than one letter (The latest was taken)\",\n",
    "    },\n",
    "    'ref' : {\n",
    "        'no_student' : \"Couldn't find a student with the specified email address\",\n",
    "        'duplicate' : \"Submitted more than one letter for the same student\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec2475-f122-4974-ac69-4f0e47802521",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(african_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57ab8a-3870-4752-9ab7-edb7c6dce504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this dictionary as a reference for column names.\n",
    "\n",
    "std_questions_dict = {i: column for i, column in enumerate(std_raw_responses_df.columns)}\n",
    "std_questions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1fde9-e160-464a-8b31-e8731237d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this dictionary as a reference for column names.\n",
    "\n",
    "ref_questions_dict = {i: column for i, column in enumerate(ref_raw_responses_df.columns)}\n",
    "ref_questions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d04d76e-c3c6-4a5e-9dac-1792ef35c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used indices of the student responses DataFrame\n",
    "\n",
    "std_idcs = {\n",
    "    'email_idx' : 1,\n",
    "    'firstname_idx' : 2,\n",
    "    'lastname_idx' : 3,\n",
    "    'nat_idx' : 5,\n",
    "    'resid_idx' : 6,\n",
    "    'cv_idx' : 23,\n",
    "    'ref' : {\n",
    "        'first_ref_email_idx' : 25,\n",
    "        'second_ref_email_idx' : 27\n",
    "          },\n",
    "    'flag_idx' : 28,\n",
    "    'notes_idx' : 29,\n",
    "    'first_recomm_letter_idx' : 30,\n",
    "    'second_recomm_letter_idx' : 31,\n",
    "}\n",
    "\n",
    "# Used indices of the reference responses DataFrame\n",
    "ref_idcs = {\n",
    "    'email_idx' : 1,\n",
    "    'name_idx' : 2,\n",
    "    'std' : {\n",
    "        'firstname_idx' : 3,\n",
    "        'lastname_idx' : 4,\n",
    "        'email_idx' : 5\n",
    "    },\n",
    "    'letter_idx' : 7,\n",
    "    'flag_idx' : 8,\n",
    "    'notes_idx' : 9,\n",
    "    'matched_idx' : 10\n",
    "}\n",
    "\n",
    "required_fields = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27]\n",
    "\n",
    "std_str_qs = [std_idcs['email_idx'], std_idcs['firstname_idx'], std_idcs['lastname_idx'], std_idcs['ref']['first_ref_email_idx'], std_idcs['ref']['second_ref_email_idx']]\n",
    "ref_str_qs = [ref_idcs['email_idx'], ref_idcs['std']['email_idx'], ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]\n",
    "\n",
    "std_names = [std_idcs['firstname_idx'], std_idcs['lastname_idx']]\n",
    "ref_names = [ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]\n",
    "\n",
    "# Carefully specify names of the columns to be processed (mostly responses for essay questions).\n",
    "essay_qs = [20, 21, 22]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44138fe5-309e-4f87-ad94-532b52df55d3",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb2db56-8054-4e0f-9ec9-0748f2937a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(answer):\n",
    "    \"\"\"\n",
    "    Takes a specific answer (cell) of a specific essay question and returns the answer's number of words.\n",
    "    \"\"\"\n",
    "    return len(answer.split())\n",
    "\n",
    "\n",
    "def to_lowercase(std_df, ref_df, std_str_qs=std_str_qs, ref_str_qs=ref_str_qs):\n",
    "    \"\"\"\n",
    "    For more rigid string comparisons, convert all answers needed for comparison to lowercase.\n",
    "    \"\"\"\n",
    "    for q in std_str_qs:\n",
    "        std_df[q] = std_df[q].str.lower()\n",
    "        \n",
    "    for q in ref_str_qs:\n",
    "        ref_df[q] = ref_df[q].str.lower()\n",
    "        \n",
    "    return std_df, ref_df\n",
    "\n",
    "\n",
    "def to_uppercase(std_df, ref_df, std_names=std_names, ref_names=ref_names):\n",
    "    \"\"\"\n",
    "    This to bring names back as they were.\n",
    "    \"\"\"\n",
    "    for q in std_names:\n",
    "        std_df[q] = std_df[q].str.title()\n",
    "        \n",
    "    for q in ref_names:\n",
    "        ref_df[q] = ref_df[q].str.title()\n",
    "        \n",
    "    return std_df, ref_df\n",
    "\n",
    "\n",
    "def remove_spaces(std_df, ref_df, std_str_qs=std_str_qs, ref_str_qs=ref_str_qs):\n",
    "    \"\"\"\n",
    "    Remove spaces from names and emails.\n",
    "    \"\"\"\n",
    "    for q in std_str_qs:\n",
    "        std_df[q] = std_df[q].str.replace(\" \", \"\")\n",
    "        std_df[q] = std_df[q].replace(\",\", \".\")\n",
    "        \n",
    "    for q in ref_str_qs:\n",
    "        ref_df[q] = ref_df[q].str.replace(\" \", \"\")\n",
    "        ref_df[q] = ref_df[q].replace(\",\", \".\")\n",
    "        \n",
    "    return std_df, ref_df\n",
    "\n",
    "\n",
    "def set_flag(responses_df, email):\n",
    "    \"\"\"\n",
    "    Sets the 'flag' column value to \"flagged\" for a response chosen by it's 'Email address'\n",
    "    \"\"\"\n",
    "    # This modifies the DataFrame itself (i.e change in place)\n",
    "    responses_df.iloc[responses_df[std_idcs['email_idx']] == email, std_idcs['flag_idx']] = \"flagged\"\n",
    "\n",
    "    \n",
    "def leave_note(responses_df, response_index, note_text):\n",
    "    \"\"\"\n",
    "    Appends a note to the 'Notes' column.\n",
    "    \"\"\"\n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    if note_text not in str(edited_responses_df.iloc[response_index, std_idcs['notes_idx']]):\n",
    "        if edited_responses_df.iloc[response_index, std_idcs['notes_idx']] is None:\n",
    "            edited_responses_df.iloc[response_index, std_idcs['notes_idx']] = note_text\n",
    "        else:\n",
    "            edited_responses_df.iloc[response_index, std_idcs['notes_idx']] = str(edited_responses_df.iloc[response_index, std_idcs['notes_idx']]) + \". \" + note_text \n",
    "            \n",
    "    return edited_responses_df\n",
    "\n",
    "\n",
    "def remove_note(responses_df, response_index, note_text):\n",
    "    \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    if note_text in str(edited_responses_df.iloc[response_index, std_idcs['notes_idx']]):\n",
    "        edited_responses_df.iloc[response_index, std_idcs['notes_idx']] = edited_responses_df.iloc[response_index, std_idcs['notes_idx']].replace(note_text + \". \", \"\")\n",
    "    \n",
    "    return edited_responses_df\n",
    "\n",
    "\n",
    "def leave_note_for_ref(ref_responses_df, response_index, note_text):\n",
    "    \"\"\"\n",
    "    Appends a note to the 'Notes' column.\n",
    "    \"\"\"\n",
    "    edited_ref_responses_df = ref_responses_df.copy()\n",
    "    \n",
    "    if note_text not in str(ref_responses_df.iloc[response_index, ref_idcs['notes_idx']]):\n",
    "        if edited_ref_responses_df.iloc[response_index, ref_idcs['notes_idx']] is None:\n",
    "            edited_ref_responses_df.iloc[response_index, ref_idcs['notes_idx']] = note_text\n",
    "        else:\n",
    "            edited_ref_responses_df.iloc[response_index, ref_idcs['notes_idx']] = str(edited_ref_responses_df.iloc[response_index, ref_idcs['notes_idx']]) + \". \" + note_text \n",
    "            \n",
    "    return edited_ref_responses_df\n",
    "\n",
    "    \n",
    "def column_names_to_indices(df, indices_dict):\n",
    "    \"\"\"\n",
    "    Replaces column names with indices.\n",
    "    \"\"\"\n",
    "    processed_df = df.rename(columns={column: i for i, column in enumerate(indices_dict.values())})\n",
    "\n",
    "    return processed_df\n",
    "\n",
    "\n",
    "def indices_to_column_names(df, indices_dict):\n",
    "    \"\"\"\n",
    "    Replaces indices with column names.\n",
    "    \"\"\"\n",
    "    processed_df = df.rename(columns={i: column for i, column in enumerate(indices_dict.values())})\n",
    "\n",
    "    return processed_df\n",
    "\n",
    "\n",
    "def remove_flagged(df):\n",
    "    \"\"\"\n",
    "    Remove f;agged columns.\n",
    "    \"\"\"\n",
    "    processed_df = df.drop(df[(df[std_idcs['flag_idx']] == 'flagged')].index)\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "\n",
    "def get_unmatched_letters(std_responses_df, ref_responses_df):\n",
    "    \"\"\"\n",
    "    Gets unmatched recommendation letters.\n",
    "    \"\"\"\n",
    "    ref_responses_df_unmatched = ref_responses_df.loc[ref_responses_df[ref_idcs['matched_idx']] == \"unmatched\"]\n",
    "\n",
    "    return ref_responses_df_unmatched\n",
    "\n",
    "\n",
    "def got_two_letters(std_responses_df):\n",
    "\n",
    "    return std_responses_df.loc[(std_responses_df[std_idcs['first_recomm_letter_idx']].notnull()) & (std_responses_df[std_idcs['second_recomm_letter_idx']].notnull())] \n",
    "\n",
    "\n",
    "def got_one_letter(std_responses_df):\n",
    "\n",
    "    return std_responses_df.loc[(std_responses_df[std_idcs['first_recomm_letter_idx']].isnull()) ^ (std_responses_df[std_idcs['second_recomm_letter_idx']].isnull())] \n",
    "\n",
    "\n",
    "def got_no_letters(std_responses_df):\n",
    "\n",
    "    return std_responses_df.loc[(std_responses_df[std_idcs['first_recomm_letter_idx']].isnull()) & (std_responses_df[std_idcs['second_recomm_letter_idx']].isnull())] \n",
    "\n",
    "\n",
    "def get_letters_counts(ref_responses_df):\n",
    "    \n",
    "    return ref_responses_df.groupby([ref_idcs['std']['email_idx']]).size().reset_index().rename(columns={0: '# letters'})\n",
    "\n",
    "\n",
    "def save_letters_stats(std_responses_df, ref_responses_df, letters_stats_dir=LETTERS_STATS_DIR):\n",
    "    \n",
    "    got_two_letters(std_responses_df).sort_values(by=[std_idcs['firstname_idx']]).to_excel(letters_stats_dir + \"/got_two_letters.xlsx\")\n",
    "    got_one_letter(std_responses_df).sort_values(by=[std_idcs['firstname_idx']]).to_excel(letters_stats_dir + \"/got_one_letter.xlsx\")\n",
    "    got_no_letters(std_responses_df).sort_values(by=[std_idcs['firstname_idx']]).to_excel(letters_stats_dir + \"/got_no_letters.xlsx\")\n",
    "    \n",
    "    get_letters_counts(ref_responses_df).to_excel(letters_stats_dir + \"/letters_counts(1 or 2).xlsx\")\n",
    "\n",
    "\n",
    "def get_flagged_stats(responses_df, flag_note, filename, notes_dict=notes_dict):\n",
    "    \n",
    "    columns = responses_df.columns\n",
    "    flagged_df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for row_index, row in responses_df.iterrows():\n",
    "    \n",
    "        if responses_df.iloc[row_index, std_idcs['flag_idx']] == \"flagged\":\n",
    "            if flag_note in str(responses_df.iloc[row_index, std_idcs['notes_idx']]):\n",
    "                flagged_df.loc[len(flagged_df.index)] = responses_df.loc[row_index].values\n",
    "    \n",
    "    indices_to_column_names(flagged_df, std_questions_dict).to_excel(FLAGGED_STATS_FOLDER_NAME + \"/\" + filename + \".xlsx\")\n",
    "        \n",
    "    return flagged_df\n",
    "\n",
    "\n",
    "def get_all_flagged_stats(responses_df, notes_dict=notes_dict):\n",
    "    \n",
    "    long_ans_df = get_flagged_stats(responses_df, notes_dict['std']['long_ans'], \"long_answers\")\n",
    "    short_ans_df = get_flagged_stats(responses_df, notes_dict['std']['short_ans'], \"short_answers\") \n",
    "    got_no_letters_df = get_flagged_stats(responses_df, notes_dict['std']['got_no_letters'], \"got_no_letters\")\n",
    "    duplicate_df = get_flagged_stats(responses_df, notes_dict['std']['duplicate'], \"duplicate_responses\")\n",
    "    traveling_abroad_df = get_flagged_stats(responses_df, notes_dict['std']['traveling_abroad'], \"traveling_abroad\")\n",
    "    non_african_df = get_flagged_stats(responses_df, notes_dict['std']['non_african'], \"non_african\")\n",
    "    no_cv_df = get_flagged_stats(responses_df, notes_dict['std']['no_cv'], \"no_cv\")\n",
    "            \n",
    "    return (long_ans_df, short_ans_df, got_no_letters_df, duplicate_df,\n",
    "            traveling_abroad_df, non_african_df, no_cv_df)\n",
    "\n",
    "\n",
    "def get_std_by_email(std_responses_df, email):\n",
    "    \n",
    "    return std_responses_df.loc[std_responses_df[std_idcs['email_idx']] == email]\n",
    "\n",
    "\n",
    "def get_ref_by_email(ref_responses_df, email):\n",
    "    \n",
    "    return ref_responses_df.loc[ref_responses_df[ref_idcs['email_idx']] == email]\n",
    "\n",
    "\n",
    "def get_ref_by_std_email(ref_responses_df, std_email):\n",
    "    \n",
    "    return ref_responses_df.loc[ref_responses_df[ref_idcs['std']['email_idx']] == std_email]\n",
    "\n",
    "\n",
    "def get_std_by_email_from_ref(ref_responses_df, std_email):\n",
    "    \n",
    "    return ref_responses_df.loc[ref_responses_df[ref_idcs['std']['email_idx']] == std_email]\n",
    "\n",
    "\n",
    "def get_std_by_firstname_from_ref(ref_responses_df, firstname):\n",
    "    \n",
    "    return ref_responses_df.loc[ref_responses_df[ref_idcs['std']['firstname_idx']] == firstname]\n",
    "\n",
    "\n",
    "def get_std_by_lastname_from_ref(ref_responses_df, lastname):\n",
    "    \n",
    "    return ref_responses_df.loc[ref_responses_df[ref_idcs['std']['lastname_idx']] == lastname]\n",
    "\n",
    "\n",
    "def get_std_by_firstname_and_lastname_from_ref(ref_responses_df, std_firstname, std_lastname):\n",
    "    \n",
    "    return ref_responses_df.loc[(ref_responses_df[ref_idcs['std']['firstname_idx']] == std_firstname) & (ref_responses_df[ref_idcs['std']['lastname_idx']] == std_lastname)]\n",
    "\n",
    "\n",
    "def get_std_by_firstname(std_responses_df, firstname):\n",
    "    \n",
    "    return std_responses_df.loc[std_responses_df[std_idcs['firstname_idx']] == firstname]\n",
    "\n",
    "\n",
    "def get_std_by_lastname(std_responses_df, lastname):\n",
    "    \n",
    "    return std_responses_df.loc[std_responses_df[std_idcs['lastname_idx']] == lastname]\n",
    "\n",
    "\n",
    "def get_std_by_firstname_and_lastname(std_responses_df, firstname, lastname):\n",
    "    \n",
    "    return std_responses_df.loc[(std_responses_df[std_idcs['firstname_idx']] == firstname) & (std_responses_df[ref_idcs['std']['lastname_idx']] == lastname)]\n",
    "\n",
    "\n",
    "def get_std_by_ref_email(std_responses_df, ref_email):\n",
    "    \n",
    "    return std_responses_df.loc[(std_responses_df[std_idcs['ref']['first_ref_email_idx']] == ref_email) | (std_responses_df[std_idcs['ref']['second_ref_email_idx']] == ref_email)]\n",
    "\n",
    "\n",
    "def get_by_nat_country(std_responses_df, country):\n",
    "    \n",
    "    return std_responses_df.loc[std_responses_df[std_idcs['nat_idx']] == country]\n",
    "    \n",
    "\n",
    "def get_by_resid_country(std_responses_df, country):\n",
    "    \n",
    "    return std_responses_df.loc[std_responses_df[std_idcs['resid_idx']] == country]\n",
    "    \n",
    "    \n",
    "def get_std_emails(std_responses_df):\n",
    "    \n",
    "    return std_responses_df.iloc[:, std_idcs['email_idx']:std_idcs['email_idx'] + 1]\n",
    "\n",
    "\n",
    "def get_ref_emails(ref_responses_df):\n",
    "    \n",
    "    return ref_responses_df.iloc[:, ref_idcs['email_idx']:ref_idcs['email_idx'] + 1]\n",
    "\n",
    "\n",
    "def get_std_names(std_responses_df):\n",
    "\n",
    "    return std_responses_df.iloc[:, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1]\n",
    "\n",
    "\n",
    "def get_ref_names(ref_responses_df):\n",
    "\n",
    "    return ref_responses_df.iloc[:, ref_idcs['name_idx']:std_idcs['name_idx'] + 1]\n",
    "\n",
    "\n",
    "def get_std_summary(std_responses_df):\n",
    "    \n",
    "    return pd.concat([std_responses_df.iloc[:, std_idcs['email_idx']:std_idcs['firstname_idx']+2], std_responses_df.iloc[:, std_idcs['flag_idx']:]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a1215f-aea3-47ee-a4e2-a91410822c4a",
   "metadata": {},
   "source": [
    "## Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93f7967-a7e6-47a4-a80c-aa765259dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(responses_df):\n",
    "    \"\"\"\n",
    "    removes duplicated rows (responses) based on 'Email address' and keeps the last response submitted.\n",
    "    Note: Some students may make changes to their responses and submit a new one,\n",
    "    this's why this function keeps the last response submitted and removes preceding ones.\n",
    "    \n",
    "    TODO: Check with the organizers what else is an adequate action.\n",
    "    \n",
    "    params :\n",
    "        response_df: the responses data (DataFrame)\n",
    "    returns:\n",
    "        edited_responses_df: An edited response_df with duplicates removed\n",
    "    \"\"\"\n",
    "    \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    edited_responses_df.drop_duplicates(subset=[std_idcs['email_idx']], keep='last')\n",
    "    \n",
    "    return edited_responses_df\n",
    "\n",
    "\n",
    "def flag_duplicates(responses_df):\n",
    "    \"\"\"\n",
    "    flags duplicated rows (responses) based on 'Email address' and keeps the last response submitted.\n",
    "    Note: Some students may make changes to their responses and submit a new one,\n",
    "    this's why this function keeps the last response submitted and flag preceding ones, and leaves a note.\n",
    "    \n",
    "    TODO: Check with the organizers what else is an adequate action.\n",
    "    \n",
    "    params :\n",
    "        response_df: the responses data (DataFrame)\n",
    "    returns:\n",
    "        edited_responses_df: An edited responses_df with 'flag' column updated\n",
    "    \"\"\"\n",
    "    \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    # Format: df['col'] = (value_if_false).where(condition, value_if_true)\n",
    "    \n",
    "    edited_responses_df[std_idcs['flag_idx']] = (edited_responses_df[std_idcs['flag_idx']]).where(\n",
    "        # True/False nupmy array - True: duplicated, False: unique (before inversion)\n",
    "        np.invert(np.array(edited_responses_df.duplicated(subset=[1], keep='last'))),\n",
    "        \"flagged\"\n",
    "    )\n",
    "\n",
    "    edited_responses_df[std_idcs['notes_idx']] = (edited_responses_df[std_idcs['notes_idx']]).where(\n",
    "        # True/False nupmy array - True: duplicated, False: unique (before inversion)\n",
    "        np.invert(np.array(edited_responses_df.duplicated(subset=[1], keep='last'))),\n",
    "        \"A duplicated response\"\n",
    "    )\n",
    "    \n",
    "    return edited_responses_df\n",
    "\n",
    "\n",
    "def flag_no_cvs(responses_df):\n",
    "    \"\"\"\n",
    "    flags students who didn't upload a CV.\n",
    "    \n",
    "    params :\n",
    "        response_df: the responses data (DataFrame)\n",
    "    returns:\n",
    "        edited_responses_df: An edited responses_df with 'flag' column updated\n",
    "    \"\"\"\n",
    "    \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    for row_index in range(len(edited_responses_df)):\n",
    "        \n",
    "        if pd.isnull(edited_responses_df.iloc[row_index, std_idcs['cv_idx']]):\n",
    "            \n",
    "            edited_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "            edited_responses_df = leave_note(edited_responses_df, row_index, \"Didn't upload a CV\")  \n",
    "\n",
    "    return edited_responses_df\n",
    "\n",
    "\n",
    "def flag_non_africans(responses_df):\n",
    "\n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    for row_index, row in edited_responses_df.iterrows():\n",
    "    \n",
    "        if FLAG_NON_AFRICANS:\n",
    "\n",
    "            if edited_responses_df.iloc[row_index, std_idcs['nat_idx']] not in african_countries:\n",
    "\n",
    "                edited_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "                edited_responses_df = leave_note(edited_responses_df, row_index, \"Non-african\")\n",
    "\n",
    "        if FLAG_TRAVELLING_ABROAD:\n",
    "\n",
    "            if edited_responses_df.iloc[row_index, std_idcs['resid_idx']] not in african_countries:\n",
    "\n",
    "                edited_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "                edited_responses_df = leave_note(edited_responses_df, row_index, \"Traveling from outside Africa\")\n",
    "        \n",
    "    return edited_responses_df\n",
    "\n",
    "\n",
    "def flag_duplicate_refs(ref_responses_df):\n",
    "    \"\"\"\n",
    "    flags duplicated reference responces (i.e. submitting multiple letters), and keep the last submitted one.\n",
    "    \n",
    "    TODO: Check with the organizers what else is an adequate action.\n",
    "    \n",
    "    params :\n",
    "        ref_response_df: the responses data (DataFrame)\n",
    "    returns:\n",
    "        edited_ref_responses_df: An edited responses_df with 'flag' column updated\n",
    "    \"\"\"\n",
    "    \n",
    "    edited_ref_responses_df = ref_responses_df.copy()\n",
    "    \n",
    "    # Format: df['col'] = (value_if_false).where(condition, value_if_true)\n",
    "    \n",
    "    edited_ref_responses_df[ref_idcs['flag_idx']] = (edited_ref_responses_df[ref_idcs['flag_idx']]).where(\n",
    "        # True/False nupmy array - True: duplicated, False: unique (before inversion)\n",
    "        np.invert(np.array(edited_ref_responses_df.duplicated(subset=[ref_idcs['email_idx'], ref_idcs['std']['email_idx']], keep='last'))),\n",
    "        \"flagged\"\n",
    "    )\n",
    "\n",
    "    edited_ref_responses_df[ref_idcs['notes_idx']] = (edited_ref_responses_df[ref_idcs['notes_idx']]).where(\n",
    "        # True/False nupmy array - True: duplicated, False: unique (before inversion)\n",
    "        np.invert(np.array(edited_ref_responses_df.duplicated(subset=[ref_idcs['email_idx'], ref_idcs['std']['email_idx']], keep='last'))),\n",
    "        \"Submitted more than one letter for the same student\"\n",
    "    )\n",
    "    \n",
    "    return edited_ref_responses_df\n",
    "\n",
    "\n",
    "def flag_refs_with_no_students(std_responses_df, ref_responses_df):\n",
    "    \"\"\"\n",
    "    Flag referees whose students didn't submit an application.\n",
    "    \"\"\"\n",
    "    \n",
    "    edited_ref_responses_df = ref_responses_df.copy()\n",
    "    \n",
    "    for ref_idx in range(len(edited_ref_responses_df)):\n",
    "        \n",
    "        if edited_ref_responses_df.iloc[ref_idx, ref_idcs['std']['email_idx']] not in std_responses_df[std_idcs['email_idx']].tolist():\n",
    "            \n",
    "            #edited_ref_responses_df.iloc[ref_idx, ref_idcs['flag_idx']] = \"flagged\"\n",
    "            edited_ref_responses_df = leave_note_for_ref(edited_ref_responses_df, ref_idx, \"Couldn't find a student with the specified email address\")  \n",
    "            \n",
    "\n",
    "    return edited_ref_responses_df\n",
    "\n",
    "\n",
    "def flag_short(responses_df, essay_qs):\n",
    "    \"\"\"\n",
    "    flags insufficently short answers (less than a specific lower limit) for a specified\n",
    "    set of essay questions, and leaves a note.\n",
    "    \n",
    "    params :\n",
    "        response_df: the responses data (DataFrame)\n",
    "        essay_qs   : essay questions (list)\n",
    "    returns:\n",
    "        edited_responses_df: An edited responses_df with short answers flagged\n",
    "    \"\"\"\n",
    "    \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    # Go through all the responses and for each response go through the answers for the essay questions\n",
    "    for row_index in range(len(edited_responses_df)):\n",
    "        \n",
    "        for question in essay_qs:\n",
    "            \n",
    "            if word_count(str(edited_responses_df.iloc[row_index, question])) < MIN_WORDS_NUM:\n",
    "                edited_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "                \n",
    "                edited_responses_df = leave_note(edited_responses_df, row_index, \"Insufficiently short answer/s\")        \n",
    "                    \n",
    "    return edited_responses_df\n",
    "                    \n",
    "\n",
    "def flag_long(responses_df, essay_qs):\n",
    "    \"\"\"\n",
    "    flags extremely long answers (more than a specific upprt limit) for a specified\n",
    "    set of essay questions, and leaves a note.\n",
    "    \n",
    "    params :\n",
    "        response_df: the responses data (DataFrame)\n",
    "        essay_qs   : essay questions (list)\n",
    "    returns:\n",
    "        edited_response_df: An edited responses_df with long answers flagged\n",
    "    \"\"\"\n",
    "     \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    # Go through all the responses and for each response go through the answers for the essay questions\n",
    "    for row_index in range(len(edited_responses_df)):\n",
    "        for question in essay_qs:\n",
    "            \n",
    "            if word_count(str(edited_responses_df.iloc[row_index, question])) > MAX_WORDS_NUM:\n",
    "                edited_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "                \n",
    "                edited_responses_df = leave_note(edited_responses_df, row_index, \"Extremely long answer/s\")\n",
    "                        \n",
    "    return edited_responses_df\n",
    "\n",
    "\n",
    "def flag_unofficial_emails(responses_df, unofficial_emails=UNOFFICIAL_EMAILS):\n",
    "    \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    for row_index in range(len(edited_responses_df)):\n",
    "        \n",
    "        try:\n",
    "            is_unofficial = any([unofficial_email in edited_responses_df.iloc[row_index, std_idcs['ref']['first_ref_email_idx']] for unofficial_email in unofficial_emails] + [unofficial_email in edited_responses_df.iloc[row_index, std_idcs['ref']['second_ref_email_idx']] for unofficial_email in unofficial_emails])\n",
    "        \n",
    "        except TypeError:\n",
    "            is_unofficial = True\n",
    "        \n",
    "        if is_unofficial:\n",
    "        \n",
    "            edited_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "            edited_responses_df = leave_note(edited_responses_df, row_index, \"Submitted a non-institutional email address for one of or both of their referees\")        \n",
    "                    \n",
    "    return edited_responses_df\n",
    "\n",
    "\n",
    "def flag_na(responses_df, required_fields=required_fields):\n",
    "    \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    if FLAG_NA:\n",
    "        \n",
    "        for row_index, row in edited_responses_df.iterrows():\n",
    "            \n",
    "            for required_field in required_fields:\n",
    "                \n",
    "                if pd.isnull(edited_responses_df.iloc[row_index, required_field]):\n",
    "\n",
    "                    edited_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "                    edited_responses_df = leave_note(edited_responses_df, row_index, \"Filled a required field with 'N/A'\")\n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "    return edited_responses_df\n",
    "\n",
    "\n",
    "def match_refs_based_on_stdn_email(std_responses_df, ref_responses_df):\n",
    "    \"\"\"\n",
    "    Matches references with the student/s they are supporting, and flags student response if they get less than the required\n",
    "    number of reference letters, and leaves a note.\n",
    "    \n",
    "    params :\n",
    "        std_responses_df : students responses data (DataFrame)\n",
    "        ref_responses_df : references responses data (DataFrame)\n",
    "    returns:\n",
    "        edited_std_responses_df: An edited std_responses_df with answers with unsatisfied conditions for recommendation letters flagged\n",
    "        ref_responses_df: The ref_responses_df but with marking the \"Matched\" column for letters those successfully matched.\n",
    "    \"\"\"\n",
    "     \n",
    "    ref_responses_df = flag_duplicate_refs(ref_responses_df)\n",
    "    edited_std_responses_df = std_responses_df.copy()\n",
    "    \n",
    "    for row_index in range(len(edited_std_responses_df)):\n",
    "        \n",
    "        if edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] is not None or edited_std_responses_df.iloc[row_index, std_idcs['second_recomm_letter_idx']] is not None:\n",
    "            continue\n",
    "            \n",
    "        # Flag student response if BOTH of their references didn't submit any letter\n",
    "        \n",
    "        if edited_std_responses_df.iloc[row_index, std_idcs['email_idx']] not in ref_responses_df[ref_idcs['std']['email_idx']].values:\n",
    "            \n",
    "            edited_std_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "            edited_std_responses_df = leave_note(edited_std_responses_df, row_index, \"Got no recommendation letters\")\n",
    "        \n",
    "        # Flag student response if ANY of their references didn't submit any letter\n",
    "        # Assign the one submitted letters to that student\n",
    "        \n",
    "        elif ref_responses_df[ref_idcs['std']['email_idx']].value_counts()[edited_std_responses_df.iloc[row_index, std_idcs['email_idx']]] == 1:\n",
    "            \n",
    "            if FLAG_ONE_LETTER:\n",
    "                edited_std_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "            \n",
    "            edited_std_responses_df = leave_note(edited_std_responses_df, row_index, \"Got only one recommendation letter\")\n",
    "            \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, ref_idcs['std']['email_idx']] == edited_std_responses_df.iloc[row_index, std_idcs['email_idx']] and ref_responses_df.iloc[ref_index, ref_idcs['flag_idx']] is None:\n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "                    \n",
    "                    break\n",
    "        \n",
    "        # This, from here below, would look much prettier with a while loop!\n",
    "    \n",
    "        # If BOTH references subnitted ONLY ONE letter,\n",
    "        # Assign the right two letters to the specific student\n",
    "        \n",
    "        elif ref_responses_df[ref_idcs['std']['email_idx']].value_counts()[edited_std_responses_df.iloc[row_index, std_idcs['email_idx']]] == 2:\n",
    "            \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] == \"matched\":\n",
    "                    continue\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, ref_idcs['std']['email_idx']] == edited_std_responses_df.iloc[row_index, std_idcs['email_idx']] and ref_responses_df.iloc[ref_index, ref_idcs['flag_idx']] is None:\n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "                    \n",
    "                    break\n",
    "                \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] == \"matched\":\n",
    "                    continue\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, ref_idcs['std']['email_idx']] == edited_std_responses_df.iloc[row_index, std_idcs['email_idx']] and edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] is not None and ref_responses_df.iloc[ref_index, ref_idcs['flag_idx']] is None:\n",
    "                    \n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['second_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "        \n",
    "        # Flag student response if one of or both their references submitted MORE THAN ONE letter\n",
    "        # And assign the right two letters to that student\n",
    "        \n",
    "        elif ref_responses_df[ref_idcs['std']['email_idx']].value_counts()[edited_std_responses_df.iloc[row_index, std_idcs['email_idx']]] > 2:\n",
    "            \n",
    "            #edited_std_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "            edited_std_responses_df = leave_note(edited_std_responses_df, row_index,\n",
    "                                                 \"Some reference/s submitted more than one letter (The latest was taken)\")\n",
    "            \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] == \"matched\":\n",
    "                    continue\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, ref_idcs['std']['email_idx']] == edited_std_responses_df.iloc[row_index, std_idcs['email_idx']] and ref_responses_df.iloc[ref_index, ref_idcs['flag_idx']] is None:\n",
    "                    \n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] == \"matched\":\n",
    "                    continue\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, ref_idcs['std']['email_idx']] == edited_std_responses_df.iloc[row_index, std_idcs['email_idx']] and edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] is not None and ref_responses_df.iloc[ref_index, ref_idcs['flag_idx']] is None:\n",
    "                    \n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['second_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "                    \n",
    "    return edited_std_responses_df, ref_responses_df\n",
    "\n",
    "\n",
    "def match_refs_based_on_stdn_name(std_responses_df, ref_responses_df):\n",
    "    \"\"\"\n",
    "    Matches references with the student/s they are supporting, and flags student response if they get less than the required\n",
    "    number of reference letters, and leaves a note.\n",
    "    \n",
    "    params :\n",
    "        std_responses_df : students responses data (DataFrame)\n",
    "        ref_responses_df : references responses data (DataFrame)\n",
    "    returns:\n",
    "        edited_std_responses_df: An edited std_responses_df with answers with unsatisfied conditions for recommendation letters flagged,\n",
    "        ref_responses_df: The ref_responses_df but with marking the \"Matched\" column for letters those successfully matched.\n",
    "    \"\"\"\n",
    "     \n",
    "    ref_responses_df = flag_duplicate_refs(ref_responses_df)\n",
    "    edited_std_responses_df = std_responses_df.copy()\n",
    "    \n",
    "    for row_index in range(len(edited_std_responses_df)):\n",
    "        \n",
    "        if edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] is not None or edited_std_responses_df.iloc[row_index, std_idcs['second_recomm_letter_idx']] is not None:\n",
    "            continue\n",
    "        \n",
    "        if len(get_std_by_firstname_and_lastname(edited_std_responses_df, edited_std_responses_df.iloc[row_index, std_idcs['firstname_idx']], edited_std_responses_df.iloc[row_index, std_idcs['lastname_idx']])) > 1:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            got_one_letter = ref_responses_df[[ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]].value_counts()[tuple(edited_std_responses_df.iloc[row_index, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1])] == 1\n",
    "        \n",
    "        except KeyError:\n",
    "            got_one_letter = False\n",
    "            \n",
    "        try:\n",
    "            got_two_letters = ref_responses_df[[ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]].value_counts()[tuple(edited_std_responses_df.iloc[row_index, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1])] == 2\n",
    "\n",
    "        except KeyError:\n",
    "            got_two_letters = False \n",
    "            \n",
    "        try:\n",
    "            got_more_than_two_letters = ref_responses_df[[ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]].value_counts()[tuple(edited_std_responses_df.iloc[row_index, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1])] > 2\n",
    "       \n",
    "        except KeyError:\n",
    "            got_more_than_two_letters = False \n",
    "        \n",
    "        if not got_one_letter and not got_two_letters and not got_more_than_two_letters:\n",
    "            got_no_letters = True\n",
    "            \n",
    "        else:\n",
    "            got_no_letters = False\n",
    "    \n",
    "        # Flag student response if BOTH of their references didn't submit any letter\n",
    "          \n",
    "        if got_no_letters:\n",
    "            \n",
    "            edited_std_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "            edited_std_responses_df = leave_note(edited_std_responses_df, row_index, \"Got no recommendation letters\")\n",
    "        \n",
    "        # Flag student response if ANY of their references didn't submit any letter\n",
    "        # Assign the one submitted letters to that student\n",
    "            \n",
    "        if got_one_letter:\n",
    "            \n",
    "            if FLAG_ONE_LETTER:\n",
    "                edited_std_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "            \n",
    "            edited_std_responses_df = leave_note(edited_std_responses_df, row_index, \"Got only one recommendation letter\")\n",
    "            \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, [ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]].tolist() == edited_std_responses_df.iloc[row_index, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1].tolist() and ref_responses_df.iloc[ref_index, ref_idcs['flag_idx']] is None:\n",
    "                    \n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "                    edited_std_responses_df = remove_note(edited_std_responses_df, row_index, \"Got no recommendation letters\")\n",
    "                    \n",
    "                    break\n",
    "        \n",
    "        # This, from here below, would look much prettier with a while loop!\n",
    "    \n",
    "        # If BOTH references subnitted ONLY ONE letter,\n",
    "        # Assign the right two letters to the specific student\n",
    "        \n",
    "        if got_two_letters:\n",
    "            \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] == \"matched\":\n",
    "                    continue\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, [ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]].tolist() == edited_std_responses_df.iloc[row_index, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1].tolist() and ref_responses_df.iloc[ref_index, ref_idcs['flag_idx']] is None:\n",
    "                    \n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "                    edited_std_responses_df = remove_note(edited_std_responses_df, row_index, \"Got no recommendation letters\")\n",
    "                    \n",
    "                    break\n",
    "                \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] == \"matched\":\n",
    "                    continue\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, [ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]].tolist() == edited_std_responses_df.iloc[row_index, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1].tolist() and edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] is not None and ref_responses_df.iloc[ref_index, ref_idcs['flag_idx']] is None:\n",
    "                    \n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['second_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "                    edited_std_responses_df = remove_note(edited_std_responses_df, row_index, \"Got no recommendation letters\")\n",
    "        \n",
    "        # Check if there are references who submitted MORE THAN ONE letter to the same student\n",
    "        # And assign the right two letters to that student\n",
    "        \n",
    "        if got_more_than_two_letters:\n",
    "            \n",
    "            edited_std_responses_df = leave_note(edited_std_responses_df, row_index,\n",
    "                                                 \"Some reference/s submitted more than one letters (The latest was taken)\")\n",
    "\n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] == \"matched\":\n",
    "                    continue\n",
    "\n",
    "                if ref_responses_df.iloc[ref_index, [ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]].tolist() == edited_std_responses_df.iloc[row_index, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1].tolist() and ref_responses_df.iloc[ref_index, ref_idcs['flag_idx']] is None:\n",
    "\n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "                    edited_std_responses_df = remove_note(edited_std_responses_df, row_index, \"Got no recommendation letters\")\n",
    "\n",
    "                    break\n",
    "\n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] == \"matched\":\n",
    "                    continue\n",
    "\n",
    "                if ref_responses_df.iloc[ref_index, [ref_idcs['std']['firstname_idx'], ref_idcs['std']['lastname_idx']]].tolist() == edited_std_responses_df.iloc[row_index, std_idcs['firstname_idx']:std_idcs['lastname_idx'] + 1].tolist() and edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] is not None and ref_responses_df.iloc[ref_index, ref_idcs['flag_idx']] is None:\n",
    "\n",
    "                    edited_std_responses_df.iloc[row_index, std_idcs['second_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                    ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "                    edited_std_responses_df = remove_note(edited_std_responses_df, row_index, \"Got no recommendation letters\")\n",
    "                    \n",
    "    return edited_std_responses_df, ref_responses_df\n",
    "\n",
    "\n",
    "def match_refs_based_on_ref_email(std_responses_df, ref_responses_df):\n",
    "    \"\"\"\n",
    "    Matches references with the student/s they are supporting, and flags student response if they get less than the required\n",
    "    number of reference letters, and leaves a note.\n",
    "    \n",
    "    params :\n",
    "        std_responses_df : students responses data (DataFrame)\n",
    "        ref_responses_df : references responses data (DataFrame)\n",
    "    returns:\n",
    "        edited_std_responses_df: An edited std_responses_df with answers with unsatisfied conditions for recommendation letters flagged,\n",
    "        ref_responses_df: The ref_responses_df but with marking the \"Matched\" column for letters those successfully matched.\n",
    "    \"\"\"\n",
    "   \n",
    "    ref_responses_df = flag_duplicate_refs(ref_responses_df)\n",
    "    edited_std_responses_df = std_responses_df.copy()\n",
    "    \n",
    "    for ref_index in range(len(ref_responses_df)):\n",
    "        \n",
    "        if ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] == \"matched\":\n",
    "                    continue\n",
    "        \n",
    "        if len(get_ref_by_email(ref_responses_df, ref_responses_df.iloc[ref_index, ref_idcs['email_idx']])) > 1:\n",
    "            continue\n",
    "        \n",
    "        if len(get_std_by_ref_email(edited_std_responses_df, ref_responses_df.iloc[ref_index, ref_idcs['email_idx']])) > 1:\n",
    "            continue\n",
    "        \n",
    "        if len(get_std_by_ref_email(edited_std_responses_df, ref_responses_df.iloc[ref_index, ref_idcs['email_idx']])) == 1:\n",
    "            \n",
    "            student = get_std_by_ref_email(edited_std_responses_df, ref_responses_df.iloc[ref_index, ref_idcs['email_idx']])\n",
    "            student_email = student.iloc[0, std_idcs['email_idx']]\n",
    "            \n",
    "            if ref_responses_df.iloc[ref_index, ref_idcs['flag_idx']] is None:\n",
    "                \n",
    "                students = get_std_by_email(edited_std_responses_df, student_email)\n",
    "                \n",
    "                for row_index, row in students.iterrows():\n",
    "                \n",
    "                    if edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] is None and ref_responses_df.iloc[ref_index, ref_idcs['flag_idx']] is None:\n",
    "\n",
    "                        edited_std_responses_df.iloc[row_index, std_idcs['first_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                        ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "                        edited_std_responses_df = remove_note(edited_std_responses_df, row_index, \"Got no recommendation letters\")\n",
    "                        \n",
    "                        break\n",
    "                                            \n",
    "                    elif edited_std_responses_df.iloc[row_index, std_idcs['second_recomm_letter_idx']] is None and ref_responses_df.iloc[ref_index, ref_idcs['flag_idx']] is None:\n",
    "\n",
    "                        edited_std_responses_df.iloc[row_index, std_idcs['second_recomm_letter_idx']] = ref_responses_df.iloc[ref_index, ref_idcs['letter_idx']]\n",
    "                        ref_responses_df.iloc[ref_index, ref_idcs['matched_idx']] = \"matched\"\n",
    "                        edited_std_responses_df = remove_note(edited_std_responses_df, row_index, \"Got no recommendation letters\")\n",
    "    \n",
    "    for row_index, row in edited_std_responses_df.iterrows():\n",
    "            \n",
    "        if bool(pd.isnull(row[std_idcs['first_recomm_letter_idx']])) != bool(pd.isnull(row[std_idcs['second_recomm_letter_idx']])):\n",
    "            \n",
    "            if FLAG_ONE_LETTER:\n",
    "                edited_std_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "                \n",
    "            edited_std_responses_df = leave_note(edited_std_responses_df, row_index, \"Got only one recommendation letter\")\n",
    "            \n",
    "        if pd.isnull(row[std_idcs['first_recomm_letter_idx']]) and pd.isnull(row[std_idcs['second_recomm_letter_idx']]):\n",
    "            \n",
    "            edited_std_responses_df.iloc[row_index, std_idcs['flag_idx']] = \"flagged\"\n",
    "            edited_std_responses_df = leave_note(edited_std_responses_df, row_index, \"Got no recommendation letters\")\n",
    "        \n",
    "    return edited_std_responses_df, ref_responses_df\n",
    "    \n",
    "\n",
    "def match_references(std_responses_df, ref_responses_df):\n",
    "    \n",
    "    edited_std_responses_df, ref_responses_df = match_refs_based_on_stdn_email(std_responses_df, ref_responses_df)\n",
    "    edited_std_responses_df, ref_responses_df = match_refs_based_on_ref_email(edited_std_responses_df, ref_responses_df)\n",
    "    edited_std_responses_df, ref_responses_df = match_refs_based_on_stdn_name(edited_std_responses_df, ref_responses_df)\n",
    "    \n",
    "    return edited_std_responses_df, ref_responses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b1027-0f5f-49fc-a338-3127be316a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(std_responses_df, ref_responses_df):\n",
    "    \n",
    "    std_responses_df = column_names_to_indices(std_responses_df, std_questions_dict)\n",
    "    ref_responses_df = column_names_to_indices(ref_responses_df, ref_questions_dict)\n",
    "    \n",
    "    responses_df_flagged_duplicates = flag_duplicates(std_responses_df)\n",
    "    responses_df_flagged_na = flag_na(responses_df_flagged_duplicates)\n",
    "    responses_df_flagged_short = flag_short(responses_df_flagged_na, essay_qs)\n",
    "    responses_df_flagged_long = flag_long (responses_df_flagged_short, essay_qs)\n",
    "    responses_df_flagged_no_cv = flag_no_cvs(responses_df_flagged_long)\n",
    "    responses_df_flagged_nonafricans = flag_non_africans(responses_df_flagged_no_cv)\n",
    "    \n",
    "    responses_df_spaces_removed, ref_responses_df_spaces_removed = remove_spaces(responses_df_flagged_nonafricans, ref_responses_df)\n",
    "    \n",
    "    responses_df_lowercase, ref_responses_df_lowercase = to_lowercase(responses_df_spaces_removed, ref_responses_df_spaces_removed)\n",
    "    \n",
    "    responses_df_matched, ref_responses_df_matched = match_references(responses_df_lowercase, ref_responses_df_lowercase)\n",
    "    ref_responses_df_final = flag_refs_with_no_students(responses_df_matched, ref_responses_df_matched)\n",
    "    \n",
    "    responses_df_final, ref_responses_df_final = to_uppercase(responses_df_matched, ref_responses_df_final)\n",
    "    \n",
    "    ref_responses_df_unmatched = get_unmatched_letters(responses_df_final, ref_responses_df_final)\n",
    "    named_ref_responses_df_unmatched = indices_to_column_names(ref_responses_df_unmatched, ref_questions_dict)\n",
    "    named_ref_responses_df_unmatched.to_excel(RESULTS_FOLDER_NAME + \"/unmatched_letters.xlsx\")\n",
    "    named_ref_responses_df_unmatched.to_excel(LETTERS_STATS_FOLDER_NAME + \"/unmatched_letters.xlsx\")\n",
    "    \n",
    "    # Putting back original column names, and saving the Excel file\n",
    "    named_responses_df_final = indices_to_column_names(responses_df_final, std_questions_dict)\n",
    "    named_responses_df_final.to_excel(RESULTS_FOLDER_NAME + \"/filtered_responses_with_flagged.xlsx\")\n",
    "    \n",
    "    save_letters_stats(responses_df_final, ref_responses_df_final)\n",
    "    \n",
    "    responses_df_final_flagged_removed = remove_flagged(responses_df_final)\n",
    "    \n",
    "    # Putting back original column names, and saving the Excel file\n",
    "    named_responses_df_final_flagged_removed = indices_to_column_names(responses_df_final_flagged_removed, std_questions_dict)\n",
    "    named_responses_df_final_flagged_removed.to_excel(RESULTS_FOLDER_NAME + \"/filtered_responses_with_flagged_removed.xlsx\")\n",
    "    \n",
    "    # Putting back original column names, and saving the Excel file\n",
    "    named_ref_responses_df_final = indices_to_column_names(ref_responses_df_final, ref_questions_dict)\n",
    "    named_ref_responses_df_final.to_excel(RESULTS_FOLDER_NAME + \"/ref_responses_with_flagged.xlsx\")\n",
    "    \n",
    "    return (responses_df_final, responses_df_final_flagged_removed,\n",
    "            ref_responses_df_final, ref_responses_df_unmatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617af5db-1174-4c1f-a02a-df41298e2195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses_df_final, responses_df_final_flagged_removed, ref_responses_df_final, ref_responses_df_unmatched = main(std_raw_responses_df, ref_raw_responses_df)\n",
    "\n",
    "long_ans_df, short_ans_df, got_no_letters_df, duplicate_df, traveling_abroad_df, non_african_df, no_cv_df = get_all_flagged_stats(responses_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bbaf72-f2bf-4bfb-bf5e-5e0da485a515",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_std_summary(responses_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d36edf2-8ddd-4a19-8e19-44ba2b93fb66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_responses_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175baf01-4029-44a3-8a40-a3be55f43bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_std_summary(responses_df_final_flagged_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828da7f4-5d6a-42d2-a6d1-6ab1564a8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(responses_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7164ec9f-60e2-41aa-9466-2eb8ffce83e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(responses_df_final_flagged_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab23400-e1ad-4fa6-8bdb-9f0c1abc242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ref_responses_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04285c86-9a1a-431b-a977-113e17c1adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ref_responses_df_unmatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aa51c2-9831-40d7-afe7-3c441ed8101a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(got_two_letters(responses_df_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c40505-04e8-4cfd-b3e7-a1ae92db5201",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(got_one_letter(responses_df_final)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adadc82a-21e3-4741-9f59-60fef17a8786",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(got_no_letters(responses_df_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8e59d-27b5-4039-93db-fb30c590fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(got_no_letters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b071e5b2-7e93-4c26-a157-76e4151fb3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(traveling_abroad_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2cb4c6-516d-428b-8ff4-dede5209ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(long_ans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c64027f-112b-4dcb-aaca-15c3c8566c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(short_ans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3e0c8d-422a-4a04-aa18-d2fbd525e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(no_cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4c958a-fe59-468d-b317-c818dda8add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_by_nat_country(responses_df_final, \"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c332c8-2b84-4836-afb3-fe79c764c0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
