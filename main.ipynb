{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86648c93-943b-4148-be8c-b86c23072b5a",
   "metadata": {},
   "source": [
    "# Applications processing Automation\n",
    "\n",
    "The purpose of this code is to automate the first trivial filtering steps in the processing of the applications for the TReND in Africa Computational Neuroscience and Machine Learning Basics course.\n",
    "\n",
    "This code is organized as a set of functions to be applied as a processing pipeline on the application responses data (See [documentation](https://docs.google.com/document/d/1n4pMEOgMuenuFpN6zXQtZlpYFXwPat2P4-SzZaN8mFg/edit?usp=drivesdk)).\n",
    "\n",
    "### **How to use (as a developer):**\n",
    "Just clone the Github repository and get into the business!\\\n",
    "If you have anaconda and yupyter installed locally you can just clone the repory directly on your machine. Elsewise, you can clone it into Google Colab.\n",
    "(In either case, don't forget to regularly pull and push changes).\n",
    "\n",
    "### **How to use (as a reviewer):**\n",
    "If you are on Github now, open this notebook in Google Colab, or clone the whole repo locally, so you can run the cells. In case of running it in Colab, don't forget to save and download the resulting Excel sheet of the processed responses into a local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5561a65-902a-424b-bc94-4b417849e29e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b154dc7-4f8f-4d8f-8417-5108fb288621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that you have to download the responses data Excel sheet from Google Drive and put it in the same folder as the code.\n",
    "# You don't have to do this if you cloned the Github repo (all will be organized in the repo).\n",
    " \n",
    "# TODO: Load data directly from Google Drive.\n",
    "\n",
    "# Loading students responses data\n",
    "#DATA_DIR = './Copy of Answers_Application_form_TReND_Comp_Neuro_FIRSTPASS.xlsx'\n",
    "STD_DATA_DIR = './dummy_students_responses_data.xlsx'\n",
    "std_raw_responses_df = pd.read_excel(STD_DATA_DIR)\n",
    "\n",
    "# Loading references responses data\n",
    "REF_DATA_DIR = './dummy_references_responses_data.xlsx'\n",
    "ref_raw_responses_df = pd.read_excel(REF_DATA_DIR)\n",
    "\n",
    "# Adding two columns to the responses DataFrame (initialized with None for all cells).\n",
    "std_raw_responses_df['Flag'] = None  #String (\"flagged\" or None)\n",
    "std_raw_responses_df['Notes'] = None #String (Text of notes == reasaons for flagging)\n",
    "std_raw_responses_df['Recommendation Letter 1'] = None\n",
    "std_raw_responses_df['Recommendation Letter 2'] = None\n",
    "\n",
    "# Flag the reference response if they submit more than one letter (keeo the last letter submitted)\n",
    "ref_raw_responses_df['Flag'] = None\n",
    "ref_raw_responses_df['Notes'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f284bde7-b704-48d6-b0c2-86e364335cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_raw_responses_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c608a3-6b4e-4f55-ae50-25c98cb33c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_raw_responses_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57ab8a-3870-4752-9ab7-edb7c6dce504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this dictionary as a reference for column names.\n",
    "\n",
    "questions_dic = {i: column for i, column in enumerate(std_raw_responses_df.columns)}\n",
    "questions_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e45a6-24aa-461b-b653-cab3d48737cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replpace column names with indices.\n",
    "\n",
    "std_responses_df = std_raw_responses_df.rename(columns={column: i for i, column in enumerate(questions_dic.values())})\n",
    "std_responses_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9765daba-961b-4024-bced-95847f8cd825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carefully specify names of the columns to be processed (mostly responses for essay questions).\n",
    "\n",
    "# TODO: To avoid any naming mistakes, replace questions, as columns names, with a key (or simply, indices).\n",
    "\n",
    "essay_qs = [13, 14, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c098d061-c2d2-41e7-8ae9-fc7f8f640ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the minimum and maximun number of words for ansewrs for essay questions.\n",
    "# Note: These parameters apply for for all essay questions.\n",
    "\n",
    "MIN_WORDS_NUM = 50\n",
    "MAX_WORDS_NUM = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44138fe5-309e-4f87-ad94-532b52df55d3",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb2db56-8054-4e0f-9ec9-0748f2937a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(answer):\n",
    "    \"\"\"\n",
    "    Takes a specific answer (cell) of a specific essay question and returns the answer's number of words.\n",
    "    \"\"\"\n",
    "    \n",
    "    return len(answer.split())\n",
    "\n",
    "\n",
    "def set_flag(responses_df, email):\n",
    "    \"\"\"\n",
    "    Sets the 'flag' column value to \"flagged\" for a response chosen by it's 'Email address'\n",
    "    \"\"\"\n",
    "    \n",
    "    # This modifies the DataFrame itself (i.e change in place)\n",
    "    # # 1 - 'Email address' column, 18 = 'flag' column\n",
    "    responses_df.iloc[responses_df[1] == email, 18] = \"flagged\"\n",
    "\n",
    "    \n",
    "def leave_note(responses_df, response_index, note_text):\n",
    "    \"\"\"\n",
    "    Appends a note to the 'Notes' column.\n",
    "    \"\"\"\n",
    "    \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    if note_text not in str(edited_responses_df.iloc[response_index, 19]):\n",
    "        if edited_responses_df.iloc[response_index, 19] is None:\n",
    "            edited_responses_df.iloc[response_index, 19] = note_text\n",
    "        else:\n",
    "            edited_responses_df.iloc[response_index, 19] = str(edited_responses_df.iloc[response_index, 19]) + \" - \" + note_text \n",
    "            \n",
    "    return edited_responses_df\n",
    "    \n",
    "    \n",
    "def index_column_names(df):\n",
    "    \"\"\"\n",
    "    Replaces column names with indices.\n",
    "    \"\"\"\n",
    "\n",
    "    indices_dic = {i: column for i, column in enumerate(df.columns)}\n",
    "    df = df.rename(columns={column: i for i, column in enumerate(indices_dic.values())})\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a1215f-aea3-47ee-a4e2-a91410822c4a",
   "metadata": {},
   "source": [
    "## Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93f7967-a7e6-47a4-a80c-aa765259dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(responses_df):\n",
    "    \"\"\"\n",
    "    removes duplicated rows (responses) based on 'Email address' and keeps the last response submitted.\n",
    "    Note: Some students may make changes to their responses and submit a new one,\n",
    "    this's why this function keeps the last response submitted and removes preceding ones.\n",
    "    \n",
    "    TODO: Check with the organizers what else is an adequate action.\n",
    "    \n",
    "    params :\n",
    "        response_df: the responses data (DataFrame)\n",
    "    returns:\n",
    "        edited_responses_df: An edited response_df with duplicates removed\n",
    "    \"\"\"\n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    # 1 = 'Email address' column\n",
    "    edited_responses_df.drop_duplicates(subset=[1], keep='last')\n",
    "    \n",
    "    return edited_responses_df\n",
    "\n",
    "\n",
    "def flag_duplicates(responses_df):\n",
    "    \"\"\"\n",
    "    flags duplicated rows (responses) based on 'Email address' and keeps the last response submitted.\n",
    "    Note: Some students may make changes to their responses and submit a new one,\n",
    "    this's why this function keeps the last response submitted and flag preceding ones, and leaves a note.\n",
    "    \n",
    "    TODO: Check with the organizers what else is an adequate action.\n",
    "    \n",
    "    params :\n",
    "        response_df: the responses data (DataFrame)\n",
    "    returns:\n",
    "        edited_responses_df: An edited responses_df with 'flag' column updated\n",
    "    \"\"\"\n",
    "    \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    # Format: df['col'] = (value_if_false).where(condition, value_if_true)\n",
    "    \n",
    "    # 18 = 'flag' column, 19 = 'notes' column\n",
    "    edited_responses_df[18] = (edited_responses_df[18]).where(\n",
    "        # True/False nupmy array - True: duplicated, False: unique (before inversion)\n",
    "        np.invert(np.array(edited_responses_df.duplicated(subset=[1], keep='last'))),\n",
    "        \"flagged\"\n",
    "    )\n",
    "    # 18 = 'flag' column, 19 = 'notes' column\n",
    "    edited_responses_df[19] = (edited_responses_df[19]).where(\n",
    "        # True/False nupmy array - True: duplicated, False: unique (before inversion)\n",
    "        np.invert(np.array(edited_responses_df.duplicated(subset=[1], keep='last'))),\n",
    "        \"A duplicated response\"\n",
    "    )\n",
    "    \n",
    "    return edited_responses_df\n",
    "\n",
    "\n",
    "def flag_duplicate_refs(ref_responses_df):\n",
    "    \"\"\"\n",
    "    flags duplicated reference responces (i.e. submitting multiple letters), and keep the last submitted one.\n",
    "    \n",
    "    TODO: Check with the organizers what else is an adequate action.\n",
    "    \n",
    "    params :\n",
    "        ref_response_df: the responses data (DataFrame)\n",
    "    returns:\n",
    "        edited_ref_responses_df: An edited responses_df with 'flag' column updated\n",
    "    \"\"\"\n",
    "    \n",
    "    edited_ref_responses_df = ref_responses_df.copy()\n",
    "    \n",
    "    # Format: df['col'] = (value_if_false).where(condition, value_if_true)\n",
    "    \n",
    "    # 18 = 'flag' column, 19 = 'notes' column\n",
    "    edited_ref_responses_df['Flag'] = (edited_ref_responses_df['Flag']).where(\n",
    "        # True/False nupmy array - True: duplicated, False: unique (before inversion)\n",
    "        np.invert(np.array(edited_ref_responses_df.duplicated(subset=['Email Address', 'Student Code'], keep='last'))),\n",
    "        \"flagged\"\n",
    "    )\n",
    "    # 18 = 'flag' column, 19 = 'notes' column\n",
    "    edited_ref_responses_df['Notes'] = (edited_ref_responses_df['Notes']).where(\n",
    "        # True/False nupmy array - True: duplicated, False: unique (before inversion)\n",
    "        np.invert(np.array(edited_ref_responses_df.duplicated(subset=['Email Address', 'Student Code'], keep='last'))),\n",
    "        \"Submitted more than one for the same student\"\n",
    "    )\n",
    "    \n",
    "    return edited_ref_responses_df\n",
    "\n",
    "\n",
    "def flag_short(responses_df, essay_qs):\n",
    "    \"\"\"\n",
    "    flags insufficently short answers (less than a specific lower limit) for a specified\n",
    "    set of essay questions, and leaves a note.\n",
    "    \n",
    "    params :\n",
    "        response_df: the responses data (DataFrame)\n",
    "        essay_qs   : essay questions (list)\n",
    "    returns:\n",
    "        edited_responses_df: An edited responses_df with short answers flagged\n",
    "    \"\"\"\n",
    "    \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    # Go through all the responses and for each response go through the answers for the essay questions\n",
    "    for row_index in range(len(edited_responses_df)):\n",
    "        for question in essay_qs:\n",
    "            \n",
    "            if word_count(str(edited_responses_df.iloc[row_index, question])) < MIN_WORDS_NUM:\n",
    "                edited_responses_df.iloc[row_index, 18] = \"flagged\"\n",
    "                \n",
    "                edited_responses_df = leave_note(edited_responses_df, row_index, \"Insufficient short answer/s\")        \n",
    "                    \n",
    "    return edited_responses_df\n",
    "                    \n",
    "\n",
    "# Should we flag long answers ??\n",
    "def flag_long(responses_df, essay_qs):\n",
    "    \"\"\"\n",
    "    flags extremely long answers (more than a specific upprt limit) for a specified\n",
    "    set of essay questions, and leaves a note.\n",
    "    \n",
    "    params :\n",
    "        response_df: the responses data (DataFrame)\n",
    "        essay_qs   : essay questions (list)\n",
    "    returns:\n",
    "        edited_response_df: An edited responses_df with long answers flagged\n",
    "    \"\"\"\n",
    "     \n",
    "    edited_responses_df = responses_df.copy()\n",
    "    \n",
    "    # Go through all the responses and for each response go through the answers for the essay questions\n",
    "    for row_index in range(len(edited_responses_df)):\n",
    "        for question in essay_qs:\n",
    "            \n",
    "            if word_count(str(edited_responses_df.iloc[row_index, question])) > MAX_WORDS_NUM:\n",
    "                edited_responses_df.iloc[row_index, 18] = \"flagged\"\n",
    "                \n",
    "                edited_responses_df = leave_note(edited_responses_df, row_index, \"Extremely long answer/s\")\n",
    "                        \n",
    "    return edited_responses_df\n",
    "\n",
    "\n",
    "def match_references(std_responses_df, ref_responses_df):\n",
    "    \"\"\"\n",
    "    flags student response if they get less than the required number of reference letters, and leaves a note.\n",
    "    \n",
    "    params :\n",
    "        std_responses_df : students responses data (DataFrame)\n",
    "        ref_responses_df : references responses data (DataFrame)\n",
    "    returns:\n",
    "        edited_std_responses_df: An edited std_responses_df with unsatisfied conditions for references letters answers flagged\n",
    "    \"\"\"\n",
    "     \n",
    "    ref_responses_df = flag_duplicate_refs(ref_responses_df)\n",
    "    edited_std_responses_df = std_responses_df.copy()\n",
    "    \n",
    "    for row_index in range(len(edited_std_responses_df)):\n",
    "        \n",
    "        # Flag student response if BOTH of their references didn't submit any letter\n",
    "        \n",
    "        if edited_std_responses_df.iloc[row_index, 1] not in ref_responses_df['Student Code'].values:\n",
    "            \n",
    "            edited_std_responses_df.iloc[row_index, 18] = \"flagged\"\n",
    "            edited_std_responses_df = leave_note(edited_std_responses_df, row_index, \"Got no reference letters\")\n",
    "        \n",
    "        # Flag student response if ANY of their references didn't submit any letter\n",
    "        # Assign the one submitted letters to that student\n",
    "        \n",
    "        elif ref_responses_df['Student Code'].value_counts()[edited_std_responses_df.iloc[row_index, 1]] == 1:\n",
    "            \n",
    "            edited_std_responses_df.iloc[row_index, 18] = \"flagged\"\n",
    "            edited_std_responses_df = leave_note(edited_std_responses_df, row_index, \"Got only one reference letter\")\n",
    "            \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.loc[ref_index, 'Student Code'] == edited_std_responses_df.iloc[row_index, 1]:\n",
    "                    edited_std_responses_df.iloc[row_index, 20] = ref_responses_df.loc[ref_index, 'Letter']\n",
    "        \n",
    "        # This, from here below, would look much prettier with a while loop!\n",
    "    \n",
    "        # If BOTH references subnitted ONLY ONE letter,\n",
    "        # Assign the right two letters to the specific student\n",
    "        \n",
    "        elif ref_responses_df['Student Code'].value_counts()[edited_std_responses_df.iloc[row_index, 1]] == 2:\n",
    "            \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.loc[ref_index, 'Student Code'] == edited_std_responses_df.iloc[row_index, 1]:\n",
    "                    edited_std_responses_df.iloc[row_index, 20] = ref_responses_df.loc[ref_index, 'Letter']\n",
    "                    \n",
    "                    break\n",
    "                \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.loc[ref_index, 'Student Code'] == edited_std_responses_df.iloc[row_index, 1] and edited_std_responses_df.iloc[row_index, 20] is not None:\n",
    "                    edited_std_responses_df.iloc[row_index, 21] = ref_responses_df.loc[ref_index, 'Letter']  \n",
    "        \n",
    "        # Flag student response if one of or both their references submitted MORE THAN ONE letter\n",
    "        # And assign the right two letters to that student\n",
    "        \n",
    "        elif ref_responses_df['Student Code'].value_counts()[edited_std_responses_df.iloc[row_index, 1]] > 2:\n",
    "            \n",
    "            #edited_std_responses_df.iloc[row_index, 18] = \"flagged\"\n",
    "            edited_std_responses_df = leave_note(edited_std_responses_df, row_index, \"Some reference/s submitted more than two letters\")\n",
    "            \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.loc[ref_index, 'Student Code'] == edited_std_responses_df.iloc[row_index, 1] and ref_responses_df.loc[ref_index, 'Flag'] is None:\n",
    "                    edited_std_responses_df.iloc[row_index, 20] = ref_responses_df.loc[ref_index, 'Letter']\n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "            for ref_index in range(len(ref_responses_df)):\n",
    "                \n",
    "                if ref_responses_df.loc[ref_index, 'Student Code'] == edited_std_responses_df.iloc[row_index, 1] and edited_std_responses_df.iloc[row_index, 20] is not None and ref_responses_df.loc[ref_index, 'Flag'] is None:\n",
    "                    edited_std_responses_df.iloc[row_index, 21] = ref_responses_df.loc[ref_index, 'Letter']\n",
    "                    \n",
    "    return edited_std_responses_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b1027-0f5f-49fc-a338-3127be316a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(responses_df):\n",
    "    \n",
    "    responses_df_flagged_duplicates = flag_duplicates(responses_df)\n",
    "    responses_df_flagged_short = flag_short(responses_df_flagged_duplicates, essay_qs)\n",
    "    responses_df_flagged_long = flag_long (responses_df_flagged_short, essay_qs)\n",
    "    \n",
    "    responses_df_final = match_references(responses_df_flagged_long, ref_raw_responses_df)\n",
    "    \n",
    "    return responses_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617af5db-1174-4c1f-a02a-df41298e2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df_final = main(std_responses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bbaf72-f2bf-4bfb-bf5e-5e0da485a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df_final.iloc[:, 18:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d567c99-fefc-435e-9701-866ad1159c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df_final.iloc[:, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15229c3-43b1-417b-b9b3-7566e92407b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_duplicate_refs(ref_raw_responses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29146021-8eb7-426f-9193-257f6593d0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
